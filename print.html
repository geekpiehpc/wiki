<!DOCTYPE HTML>
<html lang="cn" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>GeekPie_HPC Wiki</title>
                <meta name="robots" content="noindex" />
                

        <!-- Custom HTML head -->
        

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

                <link rel="icon" href="favicon.svg">
                        <link rel="shortcut icon" href="favicon.png">
                <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
                <link rel="stylesheet" href="css/print.css" media="print">
        
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
                <link rel="stylesheet" href="fonts/fonts.css">
        
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        
                <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
            </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="index.html"><strong aria-hidden="true">1.</strong> Intro</a></li><li class="chapter-item expanded "><a href="Algorithm/index.html"><strong aria-hidden="true">2.</strong> Algorithm</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="Algorithm/dgemm.html"><strong aria-hidden="true">2.1.</strong> Dgemm</a></li><li class="chapter-item expanded "><a href="Algorithm/kmer.html"><strong aria-hidden="true">2.2.</strong> Kmer</a></li></ol></li><li class="chapter-item expanded "><a href="Apps/index.html"><strong aria-hidden="true">3.</strong> Apps</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="Apps/ASC/index.html"><strong aria-hidden="true">3.1.</strong> ASC</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="Apps/ASC/asc-19/index.html"><strong aria-hidden="true">3.1.1.</strong> Asc 19</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="Apps/ASC/asc-19/cesm.html"><strong aria-hidden="true">3.1.1.1.</strong> Cesm</a></li></ol></li><li class="chapter-item expanded "><a href="Apps/ASC/asc-20/index.html"><strong aria-hidden="true">3.1.2.</strong> Asc 20</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="Apps/ASC/asc-20/quest.html"><strong aria-hidden="true">3.1.2.1.</strong> Quest</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="Apps/ISC/index.html"><strong aria-hidden="true">3.2.</strong> ISC</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="Apps/ISC/ISC-21/index.html"><strong aria-hidden="true">3.2.1.</strong> ISC 21</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="Apps/ISC/ISC-21/CodeChallenge.html"><strong aria-hidden="true">3.2.1.1.</strong> Code Challenge</a></li><li class="chapter-item expanded "><a href="Apps/ISC/ISC-21/WRF.html"><strong aria-hidden="true">3.2.1.2.</strong> WRF</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="Apps/SC/index.html"><strong aria-hidden="true">3.3.</strong> SC</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="Apps/SC/SC21/index.html"><strong aria-hidden="true">3.3.1.</strong> SC 21</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="Apps/SC/SC21/quantum-espresso.html"><strong aria-hidden="true">3.3.1.1.</strong> Quantum Espresso</a></li><li class="chapter-item expanded "><a href="Apps/SC/SC21/ramBLe.html"><strong aria-hidden="true">3.3.1.2.</strong> Ram B Le</a></li></ol></li><li class="chapter-item expanded "><a href="Apps/SC/SC20.html"><strong aria-hidden="true">3.3.2.</strong> SC 20</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="Benchmark/index.html"><strong aria-hidden="true">4.</strong> Benchmark</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="Benchmark/hpcg-dat.html"><strong aria-hidden="true">4.1.</strong> Hpcg Dat</a></li><li class="chapter-item expanded "><a href="Benchmark/hpl-dat.html"><strong aria-hidden="true">4.2.</strong> Hpl Dat</a></li><li class="chapter-item expanded "><a href="Benchmark/io500.html"><strong aria-hidden="true">4.3.</strong> Io 500</a></li></ol></li><li class="chapter-item expanded "><a href="DevOps/index.html"><strong aria-hidden="true">5.</strong> Dev Ops</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="DevOps/Grafana.html"><strong aria-hidden="true">5.1.</strong> Grafana</a></li><li class="chapter-item expanded "><a href="DevOps/LDAP.html"><strong aria-hidden="true">5.2.</strong> LDAP</a></li><li class="chapter-item expanded "><a href="DevOps/SaltStack.html"><strong aria-hidden="true">5.3.</strong> Salt Stack</a></li><li class="chapter-item expanded "><a href="DevOps/Schduler.html"><strong aria-hidden="true">5.4.</strong> Schduler</a></li><li class="chapter-item expanded "><a href="DevOps/Singularity.html"><strong aria-hidden="true">5.5.</strong> Singularity</a></li></ol></li><li class="chapter-item expanded "><a href="Language/index.html"><strong aria-hidden="true">6.</strong> Language</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="Language/C++.html"><strong aria-hidden="true">6.1.</strong> C</a></li><li class="chapter-item expanded "><a href="Language/Chisel.html"><strong aria-hidden="true">6.2.</strong> Chisel</a></li><li class="chapter-item expanded "><a href="Language/Fortran.html"><strong aria-hidden="true">6.3.</strong> Fortran</a></li><li class="chapter-item expanded "><a href="Language/Go.html"><strong aria-hidden="true">6.4.</strong> Go</a></li><li class="chapter-item expanded "><a href="Language/Rust.html"><strong aria-hidden="true">6.5.</strong> Rust</a></li></ol></li><li class="chapter-item expanded "><a href="Libs/index.html"><strong aria-hidden="true">7.</strong> Libs</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="Libs/Boost.html"><strong aria-hidden="true">7.1.</strong> Boost</a></li></ol></li><li class="chapter-item expanded "><a href="Profiling/index.html"><strong aria-hidden="true">8.</strong> Profiling</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="Profiling/ArmForge.html"><strong aria-hidden="true">8.1.</strong> Arm Forge</a></li><li class="chapter-item expanded "><a href="Profiling/uProf.html"><strong aria-hidden="true">8.2.</strong> Uprof</a></li><li class="chapter-item expanded "><a href="Profiling/Vtune.html"><strong aria-hidden="true">8.3.</strong> Vtune</a></li></ol></li><li class="chapter-item expanded "><a href="Sysadmin/index.html"><strong aria-hidden="true">9.</strong> Sysadmin</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="Sysadmin/cluster-setup.html"><strong aria-hidden="true">9.1.</strong> Cluster Setup</a></li><li class="chapter-item expanded "><a href="Sysadmin/environment-installation.html"><strong aria-hidden="true">9.2.</strong> Environment Installation</a></li><li class="chapter-item expanded "><a href="Sysadmin/environment-modules.html"><strong aria-hidden="true">9.3.</strong> Environment Modules</a></li><li class="chapter-item expanded "><a href="Sysadmin/machine.html"><strong aria-hidden="true">9.4.</strong> Machine</a></li></ol></li></ol>            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                                                <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                                            </div>

                    <h1 class="menu-title">GeekPie_HPC Wiki</h1>

                    <div class="right-buttons">
                                                <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                                                                        <a href="https://github.com/geekpiehpc/wiki" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                                                
                    </div>
                </div>

                                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p>é¦–å…ˆï¼Œæ¬¢è¿å¤§å®¶åŠ å…¥<code>GeekPie_HPC</code>ï¼Œè¿™æ˜¯ä¸€ä¸ªæŠ€æœ¯ä¸­ç«‹ï¼Œç«‹å¿—å’Œæ¸…åæ¯”è‚©çš„æ¯”èµ›é˜Ÿä¼ã€‚æˆ‘ä»¬é‡è§†è¾“èµ¢çš„åŒæ—¶ï¼Œæ›´ç€é‡åŸ¹å…»çš„æ˜¯å¤§å®¶çš„å®è·µï¼ˆå¯¹å„ç§å·¥å…·çš„ç†Ÿç»ƒåº”ç”¨ï¼‰èƒ½åŠ›ï¼Œäº¤æµï¼ˆæ“…é•¿ç”»é¥¼ï¼Œæ¥é”…å’Œå†é€ è¡€ï¼‰èƒ½åŠ›ã€‚å¦‚æœä½ éœ€è¦èŠ±ç»å¤§å¤šæ•°çš„æ—¶é—´å· GPAï¼Œæœ¬ç¤¾ä¸æ¬¢è¿ä½ ï¼Œç”±äºæ¯”èµ›å‡ ä¹æ‰€æœ‰æ—¶é—´éƒ½è½åœ¨æœŸä¸­æœŸæœ«è€ƒè¯•å·¦å³ï¼Œæˆ‘ä»¬å¸Œæœ›çš„æ˜¯ YOLO çš„ç²¾ç¥ã€‚</p>
<p>æœ‰å…³å¦‚ä½•åšä¸€ä¸ª<a href="https://coolshell.cn/articles/17497.html">å¥½çš„æŠ€æœ¯åˆ†äº«å®˜</a>ï¼Œæ— è®ºæ˜¯å­¦æœ¯ã€ç§‘ç ”ï¼Œéƒ½æ˜¯åœ¨å’Œåˆ«äºº brain storm çš„åŒæ—¶äº§ç”Ÿä»·å€¼ã€‚ä½ åšçš„å·¥ä½œï¼Œåªæœ‰å¯¹åˆ«äººäº§ç”Ÿäº†ä»·å€¼ï¼Œåˆ«äººæ‰ä¼š value ä½ ï¼Œå…‰åšä¸€ä¸ªæŠ€æœ¯å¼ºè€…æ˜¯æ¯«æ— ä½œç”¨çš„ã€‚å¸Œæœ›å¤§å®¶çæƒœä¸ä¼˜ç§€çš„äººå…±äº‹çš„æœºä¼šï¼Œåœ¨ slackã€å‘¨ä¼šä¸Šçœ‹çœ‹åˆ«äººæ˜¯æ€ä¹ˆåšçš„ï¼Œç„¶åè‡ªå·±ä¹Ÿè´¡çŒ®äº›åŠ›æ‰€èƒ½åŠçš„äº‹ã€‚</p>
<p>è¿™é‡Œæ˜¯<code>GeekPie_HPC</code>æ‰˜ç®¡åœ¨<code>github pages</code>çš„ç¬¬ä¸‰ä¸ªwikiï¼Œæœ‰ä¸€éƒ¨åˆ†åœ¨geekpieçš„<code>wiki.js</code>é‡Œï¼Œè¿˜æœ‰ä¸€å°éƒ¨åˆ†åœ¨geekpieæ ¡å†…æœåŠ¡å™¨çš„conferenceä¸Šï¼Œä¸ºäº†é¿å…æœ‰ä¸€å¤©è¿ç»´åˆ åº“è·‘è·¯ï¼Œæ‰€ä»¥å…ˆæ”¾githubä¸Šï¼Œä½¿ç”¨<code>github actions</code>è‡ªåŠ¨ç”Ÿæˆ<code>gitbook</code>ã€‚</p>
<p>éœ€è¦æ–°åŠ æ–‡æ¡£è¯·ç›´æ¥åœ¨<code>main</code> branchä¸Šæäº¤<code>markdown</code>æ–‡ä»¶ï¼Œåœ¨åŠåˆ†é’Ÿä¹‹å<a href="http://hpc.geekpie.club/wiki/">wiki</a>å°±ä¼šå¾—åˆ°æ›´æ–°ã€‚</p>
<h2 id="ç›®å‰wikiç»´æŠ¤"><a class="header" href="#ç›®å‰wikiç»´æŠ¤">ç›®å‰wikiç»´æŠ¤</a></h2>
<p>murez å¯ä»¥åœ¨ç™½è£™å’ŒHPCç¾¤æ‰¾åˆ°ã€‚å‘½åé‡‡ç”¨å°ç«¯å¤§å†™æ³•ã€‚éœ€è¦pushå³å¯ã€‚</p>
<h2 id="æœ‰å…³å‡ºå…¥å£"><a class="header" href="#æœ‰å…³å‡ºå…¥å£">æœ‰å…³å‡ºå…¥å£</a></h2>
<p><a href="https://hpc.geekpie.club/archives/">æ‹›æ–°å…¬å‘Š</a>ï¼Œ<a href="https://geekpiehpc.slack.com">slack</a>ç”¨ä¸Šç§‘å¤§é‚®ç®±å¯ä»¥æ³¨å†Œï¼Œæš‘æœŸæƒ³å®ä¹ ã€ç£•ç›å¯ä»¥åœ¨é»‘è£™é‡Œæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚æ ¡å†…ä¸å®šæœŸé‚€è¯·å¤–æ ¡åŒå­¦å’ŒåŒäº‹å’Œå…±äº‹è€…æ¼”è®²ã€‚</p>
<p><em>Generated <a href="http://hpc.geekpie.club/wiki/">GitHub Pages</a> is powered by <a href="https://github.com/rust-lang/mdBook">mdBook</a>.</em></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="algorithm"><a class="header" href="#algorithm">Algorithm</a></h1>
<p>è¿™é‡Œæ”¾ç½®æœ‰å…³åº”ç”¨å’Œæµ‹è¯•ä¸­å¸¸è§çš„ç®—æ³•ã€‚</p>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><h1 id="applications"><a class="header" href="#applications">Applications</a></h1>
<p>è¿™é‡Œæ”¾ç½®<code>GeekPie_HPC</code>å‚ä¸è¿‡å„ä¸ªç«èµ›ä¸­çš„åº”ç”¨çš„ç»å†å’Œç»éªŒã€‚</p>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><!-- TITLE: CESM -->
<!-- SUBTITLE: CESM summary -->
<h1 id="cesm"><a class="header" href="#cesm">CESM</a></h1>
<h2 id="build--running"><a class="header" href="#build--running">Build &amp; Running</a></h2>
<h3 id="onekeyconf"><a class="header" href="#onekeyconf">OneKeyConf</a></h3>
<pre><code class="language-bash">./create_newcase -res 0.47x0.63_gx1v6 -compset B -case ../EXP2 -mach pleiades-ivy
mkdir nobackup
ln -s /home/cesm/data/inputdata_EXP1/ nobackup/inputdata
# EXP1: ./xmlchange -file env_run.xml -id DOCN_SOM_FILENAME -val pop_frc.gx1v6.091112.nc
./xmlchange -file env_build.xml -id CESMSCRATCHROOT -val `pwd`'/nobackup/$USER'
./xmlchange -file env_build.xml -id EXEROOT -val `pwd`'/nobackup/$CCSMUSER/$CASE/bld'
./xmlchange -file env_run.xml -id RUNDIR -val `pwd`'/nobackup/$CCSMUSER/$CASE/run'
./xmlchange -file env_run.xml -id DIN_LOC_ROOT -val `pwd`'/nobackup/inputdata'
./xmlchange -file env_run.xml -id DIN_LOC_ROOT_CLMFORC -val `pwd`'/nobackup/inputdata/atm/datm7'
./xmlchange -file env_run.xml -id DOUT_S_ROOT -val `pwd`'/nobackup/$CCSMUSER/archive/$CASE'
./xmlchange -file env_run.xml -id RUN_STARTDATE -val 2000-01-01
./xmlchange -file env_build.xml -id BUILD_THREADED -val TRUE
# edit Macro SLIBS -lnetcdff
# edit env_mach_specific
./cesm_setup
</code></pre>
<h3 id="ybssh"><a class="header" href="#ybssh">ybs.sh</a></h3>
<pre><code class="language-bash">./EXP2.clean_build all
./cesm_setup -clean
rm -rf $build_dir
./cesm_setup
./EXP2.build
</code></pre>
<h3 id="pbs"><a class="header" href="#pbs">PBS</a></h3>
<pre><code>##PBS -N dappur
##PBS -q pub_blad_2
##PBS -j oe
##PBS -l walltime=00:01:00
##PBS -l nodes=1:ppn=28
</code></pre>
<h2 id="performance-tuning"><a class="header" href="#performance-tuning">Performance Tuning</a></h2>
<h2 id="trouble-shooting"><a class="header" href="#trouble-shooting">Trouble Shooting</a></h2>
<h3 id="high-sys-percentage-in-top-20"><a class="header" href="#high-sys-percentage-in-top-20">High sys percentage in top (&gt;20%)</a></h3>
<p>This is apparent this is a communication problem. Try switching to Intel MPI for a terribly low sys percentage (&lt;1%).</p>
<h3 id="error-remap-transport-bad-departure-points"><a class="header" href="#error-remap-transport-bad-departure-points">ERROR: remap transport: bad departure points</a></h3>
<pre><code>Warning: Departure points out of bounds in remap                  
 my_task, i, j =         182           4           8              
 dpx, dpy =  -5925130.21408796      -0.368922055964299            
 HTN(i,j), HTN(i+1,j) =   72848.1354852604        72848.1354852604
 HTE(i,j), HTE(i,j+1) =   59395.4550164223        59395.4550164223
 istep1, my_task, iblk =     1095001         182           1      
 Global block:         205                                        
 Global i and j:          35          47                          
(shr_sys_abort) ERROR: remap transport: bad departure points      
(shr_sys_abort) WARNING: calling shr_mpi_abort() and stopping     
application called MPI_Abort(MPI_COMM_WORLD, 1001) - process 182
</code></pre>
<p>This error may due to multiple reasons.</p>
<p>One significant one is the bad grid division. We were once using one PE for every processor core so the total number of PEs is not a power of 2. Then we used 128 (or later 256) and the error diminished until it showed up again after 6mos of simulation...</p>
<p>Then another affecting reason is the parameter xndt_dyn, see link. This parameter has already been set to 2 after solving the last problem (originally 1). Then we tried increasing this parameter again, it passed the 6mos simulation, but crashed again after another 3mos. We then continued increasing the value, but it crashes faster. We stopped at about 20mos simulation and turned to GNU compiler version with Intel MPI.</p>
<p>However, this does not mean it's the fault of Intel compiler. Direct comparison between Intel and GNU compilers is unfair because the combination of Intel compiler xndt_dyn=1 and most importantly the correct PE number has not been tried. Maybe try using xndt_dyn=1 from be beginning next time, using Intel compiler.</p>
<h3 id="openmp-failed"><a class="header" href="#openmp-failed">OpenMP failed</a></h3>
<p>Still no solved, but very promising for improving performance.</p>
<p>fixed in <a href="Apps/ASC/asc-19/../../ISC/ISC-21/WRF.html">WRF</a></p>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><!-- TITLE: Quest -->
<!-- SUBTITLE: A quick summary of Quest -->
<h1 id="quest-analysis"><a class="header" href="#quest-analysis">quest analysis</a></h1>
<h2 id="program-goal-analysis"><a class="header" href="#program-goal-analysis">program goal analysis</a></h2>
<p>what's code is actually doing is to simulate quantum computing.</p>
<p><img src="Apps/ASC/asc-20/./quest-circuit.png" alt="" /></p>
<h3 id="different-bits-state---qubits"><a class="header" href="#different-bits-state---qubits">different bits state - qubits</a></h3>
<p>3 states: <code>1</code> <code>0</code> <code>0/1</code></p>
<p>store by qreal which is actualy a complex number a+bi  (a+b=1), and it can be stated as \( (\begin{smallmatrix}0.123124&amp;0\ 0&amp;0.876876\end{smallmatrix}) \) , also note that because gpu only support float32 computing. So native qreal (precision=4) is not supported in gpu simutation.</p>
<pre><code class="language-cpp">/*
 * Single precision, which uses 4 bytes per amplitude component
 */
# if QuEST_PREC==1
    # define qreal float
    // \cond HIDDEN_SYMBOLS   
    # define MPI_QuEST_REAL MPI_FLOAT
    # define MPI_MAX_AMPS_IN_MSG (1LL&lt;&lt;29) // must be 2^int
    # define REAL_STRING_FORMAT &quot;%.8f&quot;
    # define REAL_QASM_FORMAT &quot;%.8g&quot;
    # define REAL_EPS 1e-5
    # define absReal(X) fabs(X) // not fabsf(X) - better to return doubles where possible
    // \endcond
/*
 * Double precision, which uses 8 bytes per amplitude component
 */
# elif QuEST_PREC==2
    # define qreal double
    // \cond HIDDEN_SYMBOLS   
    # define MPI_QuEST_REAL MPI_DOUBLE
    # define MPI_MAX_AMPS_IN_MSG (1LL&lt;&lt;28) // must be 2^int
    # define REAL_STRING_FORMAT &quot;%.14f&quot;
    # define REAL_QASM_FORMAT &quot;%.14g&quot;
    # define REAL_EPS 1e-13
    # define absReal(X) fabs(X)
    // \endcond
/*
 * Quad precision, which uses 16 bytes per amplitude component.
 * This is not compatible with most GPUs.
 */
# elif QuEST_PREC==4
    # define qreal long double
    // \cond HIDDEN_SYMBOLS   
    # define MPI_QuEST_REAL MPI_LONG_DOUBLE
    # define MPI_MAX_AMPS_IN_MSG (1LL&lt;&lt;27) // must be 2^int
    # define REAL_STRING_FORMAT &quot;%.17Lf&quot;
    # define REAL_QASM_FORMAT &quot;%.17Lg&quot;
    # define REAL_EPS 1e-14
    # define absReal(X) fabsl(X)
    // \endcond
# endif
</code></pre>
<h3 id="many-matrices-computation"><a class="header" href="#many-matrices-computation">many matrices computation</a></h3>
<img src="Apps/ASC/asc-20/./image-20200206182352740.png" alt="image-20200206182352740" style="zoom:33%;" />
<p>all of the gate corresponds to one of the manipulation on qubits.</p>
<h4 id="basic-operation-on-a-and-b-httpsarxivorgpdfquant-ph0207118pdf"><a class="header" href="#basic-operation-on-a-and-b-httpsarxivorgpdfquant-ph0207118pdf">Basic operation on a and b https://arxiv.org/pdf/quant-ph/0207118.pdf</a></h4>
<p>random variables = density matrix </p>
<p><strong>hermitian</strong>:\(\rho^{\dagger}=\rho\)</p>
<p><strong>positive semidefinite</strong>:  <strong>eigenvalue</strong> \(\geq\) 0</p>
<p><strong>trace</strong>: \(\Sigma(diagnal\ elements)=1\)</p>
<p>dirac notation: ket \(v_{\phi}=|\phi\rangle=\left(\begin{array}{l}\phi_{0} \\phi_{1}\end{array}\right)\)</p>
<p>bra   \( v_{\phi}^{\dagger}=\langle\phi|=\left(\begin{array}{ll}\phi_{0} &amp; \phi_{1}\end{array}\right)\)</p>
<p>\(\langle\phi \mid \psi\rangle\)= inner products of bra(fi) and ket(theta). notice: \(\langle\phi \mid \phi\rangle=1\)</p>
<p>\(|\phi\rangle|\psi\rangle\)=tensor product of ket(fi) and bra(theta)</p>
<p>2 special notation: \(u_{0}=|0\rangle=\left(\begin{array}{l}1 \ 0\end{array}\right) \quad v_{1}=|1\rangle=\left(\begin{array}{l}0 \ 1\end{array}\right)\)</p>
<p>the dense <strong>matrix</strong>:\(\rho=\left(\begin{array}{cc}q_{0} &amp; 0 \ 0 &amp; q_{1}\end{array}\right)\) (\(q_{0}+q_{1}=1\), the purpose of the equation is to illustrate the complex number ) can be stated  as \(\rho=q_{0}|0\rangle\left\langle 0\left|+q_{1}\right| 1\right\rangle\langle 1|\)</p>
<p>so \(\rho|0\rangle=\left(q_{0}|0\rangle\left\langle 0\left|+q_{1}\right| 1\right\rangle\langle 1|\right)|0\rangle=q_{0}|0\rangle\)</p>
<p>dot product (from normal bits to qubits):\( |a b\rangle=|a\rangle \otimes|b\rangle=v_{00}|00\rangle+v_{01}|01\rangle+v_{10}|10\rangle \dashv v_{11}|11\rangle \rightarrow\left[\begin{array}{l}v_{00} \ v_{01} \ v_{10} \ v_{11}\end{array}\right] \)</p>
<p>for example in bits 5 = 101b, while in qubits \(|5\rangle_{3}=|101\rangle=|1\rangle|0\rangle|1\rangle=\left(\begin{array}{l}0 \ 1\end{array}\right)\left(\begin{array}{l}1 \ 0\end{array}\right)\left(\begin{array}{l}0 \ 1\end{array}\right)=\left(\begin{array}{l}0 \ 0 \ 0 \ 0 \ 0 \ 1 \ 0 \ 0\end{array}\right)\)</p>
<p><img src="Apps/ASC/asc-20/image-20200206193126579.png" alt="" /></p>
<h4 id="hadamard-gate-operations"><a class="header" href="#hadamard-gate-operations">Hadamard gate operations</a></h4>
<p>\begin{aligned}H(|0\rangle) &amp;=\frac{1}{\sqrt{2}}|0\rangle+\frac{1}{\sqrt{2}}|1\rangle=:|+\rangle \end{aligned}</p>
<p>\begin{aligned} H(|1\rangle) &amp;=\frac{1}{\sqrt{2}}|0\rangle-\frac{1}{\sqrt{2}}|1\rangle=:|-\rangle \end{aligned}</p>
<p>\begin{aligned} H\left(\frac{1}{\sqrt{2}}|0\rangle+\frac{1}{\sqrt{2}}|1\rangle\right) &amp;=\frac{1}{2}(|0\rangle+|1\rangle)+\frac{1}{2}(|0\rangle-|1\rangle)=|0\rangle \end{aligned}</p>
<p>\begin{aligned} H\left(\frac{1}{\sqrt{2}}|0\rangle-\frac{1}{\sqrt{2}}|1\rangle\right) &amp;=\frac{1}{2}(|0\rangle+|1\rangle)-\frac{1}{2}(|0\rangle-|1\rangle)=|1\rangle\end{aligned}</p>
<p>corresponding matrix operation in dirac notation: \(H_{1}=\frac{1}{\sqrt{2}}\left(\begin{array}{cc}1 &amp; 1 \ 1 &amp; -1\end{array}\right)\)</p>
<p>some specialty:</p>
<ol>
<li>\(H=\frac{|0\rangle+|1\rangle}{\sqrt{2}}\langle 0|+\frac{|0\rangle-|1\rangle}{\sqrt{2}}\langle 1|\)</li>
<li>Since \(HH^{\dagger}=I\) where <em>I</em> is the identity matrix, <em>H</em> is a <a href="https://en.wikipedia.org/wiki/Unitary_matrix">unitary matrix</a> (like all other quantum logical gates). Also, it is its own <a href="https://en.wikipedia.org/wiki/Unitary_matrix">unitary inverse</a>, \(H=H^{\dagger}\).</li>
</ol>
<p>One application of the Hadamard gate to either a 0 or 1 qubit will produce a quantum state that, if observed, will be a 0 or 1 with equal probability (as seen in the first two operations). This is exactly like flipping a fair coin in the standard <a href="https://en.wikipedia.org/wiki/Probabilistic_Turing_machine">probabilistic model of computation</a>. However, if the Hadamard gate is applied twice in succession (as is effectively being done in the last two operations), then the final state is always the same as the initial state.</p>
<pre><code class="language-cpp">__global__ void statevec_hadamardKernel (Qureg qureg, const int targetQubit){
    // ----- sizes
    long long int sizeBlock,                                           // size of blocks
         sizeHalfBlock;                                       // size of blocks halved
    // ----- indices
    long long int thisBlock,                                           // current block
         indexUp,indexLo;                                     // current index and corresponding index in lower half block

    // ----- temp variables
    qreal   stateRealUp,stateRealLo,                             // storage for previous state values
           stateImagUp,stateImagLo;                             // (used in updates)
    // ----- temp variables
    long long int thisTask;                                   // task based approach for expose loop with small granularity
    const long long int numTasks=qureg.numAmpsPerChunk&gt;&gt;1;

    sizeHalfBlock = 1LL &lt;&lt; targetQubit;                               // size of blocks halved
    sizeBlock     = 2LL * sizeHalfBlock;                           // size of blocks

    // ---------------------------------------------------------------- //
    //            rotate                                                //
    // ---------------------------------------------------------------- //

    //! fix -- no necessary for GPU version
    qreal *stateVecReal = qureg.deviceStateVec.real;
    qreal *stateVecImag = qureg.deviceStateVec.imag;

    qreal recRoot2 = 1.0/sqrt(2.0);

    thisTask = blockIdx.x*blockDim.x + threadIdx.x;
    if (thisTask&gt;=numTasks) return;

    thisBlock   = thisTask / sizeHalfBlock;
    indexUp     = thisBlock*sizeBlock + thisTask%sizeHalfBlock;
    indexLo     = indexUp + sizeHalfBlock;

    // store current state vector values in temp variables
    stateRealUp = stateVecReal[indexUp];
    stateImagUp = stateVecImag[indexUp];

    stateRealLo = stateVecReal[indexLo];
    stateImagLo = stateVecImag[indexLo];

    stateVecReal[indexUp] = recRoot2*(stateRealUp + stateRealLo);
    stateVecImag[indexUp] = recRoot2*(stateImagUp + stateImagLo);

    stateVecReal[indexLo] = recRoot2*(stateRealUp - stateRealLo);
    stateVecImag[indexLo] = recRoot2*(stateImagUp - stateImagLo);
}

void statevec_hadamard(Qureg qureg, const int targetQubit) 
{
    int threadsPerCUDABlock, CUDABlocks;
    threadsPerCUDABlock = 128;
    CUDABlocks = ceil((qreal)(qureg.numAmpsPerChunk&gt;&gt;1)/threadsPerCUDABlock);
    statevec_hadamardKernel&lt;&lt;&lt;CUDABlocks, threadsPerCUDABlock&gt;&gt;&gt;(qureg, targetQubit);
}
</code></pre>
<h4 id="pauli-xyz-gate"><a class="header" href="#pauli-xyz-gate">Pauli-X/Y/Z gate</a></h4>
<p>The Pauli-X gate acts on a single qubit. It is the quantum equivalent of the \( X=\left[\begin{array}{ll}0 &amp; 1 \ 1 &amp; 0\end{array}\right]\)</p>
<pre><code class="language-cpp">void pauliX(Qureg qureg, const int targetQubit) {
    validateTarget(qureg, targetQubit, __func__);
    
    statevec_pauliX(qureg, targetQubit);
    if (qureg.isDensityMatrix) {
        statevec_pauliX(qureg, targetQubit+qureg.numQubitsRepresented);
    }
    
    qasm_recordGate(qureg, GATE_SIGMA_X, targetQubit);
}
</code></pre>
<p>the real computing part</p>
<pre><code class="language-cpp">void statevec_pauliXLocal(Qureg qureg, const int targetQubit)
{
    long long int sizeBlock, sizeHalfBlock;
    long long int thisBlock, // current block
         indexUp,indexLo;    // current index and corresponding index in lower half block

    qreal stateRealUp,stateImagUp;
    long long int thisTask;         
    const long long int numTasks=qureg.numAmpsPerChunk&gt;&gt;1;

    // set dimensions
    sizeHalfBlock = 1LL &lt;&lt; targetQubit;  
    sizeBlock     = 2LL * sizeHalfBlock; 

    // Can't use qureg.stateVec as a private OMP var
    qreal *stateVecReal = qureg.stateVec.real;
    qreal *stateVecImag = qureg.stateVec.imag;

# ifdef _OPENMP
# pragma omp parallel \
    default  (none) \
    shared   (sizeBlock,sizeHalfBlock, stateVecReal,stateVecImag) \
    private  (thisTask,thisBlock ,indexUp,indexLo, stateRealUp,stateImagUp) 
# endif
    {
# ifdef _OPENMP
# pragma omp for schedule (static)
# endif
        for (thisTask=0; thisTask&lt;numTasks; thisTask++) {
            thisBlock   = thisTask / sizeHalfBlock;
            indexUp     = thisBlock*sizeBlock + thisTask%sizeHalfBlock;
            indexLo     = indexUp + sizeHalfBlock;

            stateRealUp = stateVecReal[indexUp];
            stateImagUp = stateVecImag[indexUp];

            stateVecReal[indexUp] = stateVecReal[indexLo];
            stateVecImag[indexUp] = stateVecImag[indexLo];

            stateVecReal[indexLo] = stateRealUp;
            stateVecImag[indexLo] = stateImagUp;
        } 
    }

}

void statevec_pauliXDistributed (Qureg qureg,
        ComplexArray stateVecIn,
        ComplexArray stateVecOut)
{

    long long int thisTask;  
    const long long int numTasks=qureg.numAmpsPerChunk;

    qreal *stateVecRealIn=stateVecIn.real, *stateVecImagIn=stateVecIn.imag;
    qreal *stateVecRealOut=stateVecOut.real, *stateVecImagOut=stateVecOut.imag;

# ifdef _OPENMP
# pragma omp parallel \
    default  (none) \
    shared   (stateVecRealIn,stateVecImagIn,stateVecRealOut,stateVecImagOut) \
    private  (thisTask)
# endif
    {
# ifdef _OPENMP
# pragma omp for schedule (static)
# endif
        for (thisTask=0; thisTask&lt;numTasks; thisTask++) {
            stateVecRealOut[thisTask] = stateVecRealIn[thisTask];
            stateVecImagOut[thisTask] = stateVecImagIn[thisTask];
        }
    }
} 
</code></pre>
<pre><code class="language-cpp">__global__ void statevec_pauliXKernel(Qureg qureg, const int targetQubit){
    // ----- sizes
    long long int sizeBlock,                                           // size of blocks
         sizeHalfBlock;                                       // size of blocks halved
    // ----- indices
    long long int thisBlock,                                           // current block
         indexUp,indexLo;                                     // current index and corresponding index in lower half block

    // ----- temp variables
    qreal   stateRealUp,                             // storage for previous state values
           stateImagUp;                             // (used in updates)
    // ----- temp variables
    long long int thisTask;                                   // task based approach for expose loop with small granularity
    const long long int numTasks=qureg.numAmpsPerChunk&gt;&gt;1;

    sizeHalfBlock = 1LL &lt;&lt; targetQubit;                               // size of blocks halved
    sizeBlock     = 2LL * sizeHalfBlock;                           // size of blocks

    // ---------------------------------------------------------------- //
    //            rotate                                                //
    // ---------------------------------------------------------------- //

    //! fix -- no necessary for GPU version
    qreal *stateVecReal = qureg.deviceStateVec.real;
    qreal *stateVecImag = qureg.deviceStateVec.imag;

    thisTask = blockIdx.x*blockDim.x + threadIdx.x;
    if (thisTask&gt;=numTasks) return;

    thisBlock   = thisTask / sizeHalfBlock;
    indexUp     = thisBlock*sizeBlock + thisTask%sizeHalfBlock;
    indexLo     = indexUp + sizeHalfBlock;

    // store current state vector values in temp variables
    stateRealUp = stateVecReal[indexUp];
    stateImagUp = stateVecImag[indexUp];

    stateVecReal[indexUp] = stateVecReal[indexLo];
    stateVecImag[indexUp] = stateVecImag[indexLo];

    stateVecReal[indexLo] = stateRealUp;
    stateVecImag[indexLo] = stateImagUp;
}

void statevec_pauliX(Qureg qureg, const int targetQubit) 
{
    int threadsPerCUDABlock, CUDABlocks;
    threadsPerCUDABlock = 128;
    CUDABlocks = ceil((qreal)(qureg.numAmpsPerChunk&gt;&gt;1)/threadsPerCUDABlock);
    statevec_pauliXKernel&lt;&lt;&lt;CUDABlocks, threadsPerCUDABlock&gt;&gt;&gt;(qureg, targetQubit);
}
</code></pre>
<h2 id="source-code-analysis"><a class="header" href="#source-code-analysis">source code analysis</a></h2>
<h4 id="tree"><a class="header" href="#tree">tree</a></h4>
<pre><code class="language-bash">.
â”œâ”€â”€ CMakeLists.txt
â”œâ”€â”€ include
â”‚   â”œâ”€â”€ QuEST_complex.h				 //determine to use native external cpp support or c complex support.
â”‚   â”œâ”€â”€ QuEST.h								  //main func claim
â”‚   â””â”€â”€ QuEST_precision.h				//define the precision
â””â”€â”€ src
    â”œâ”€â”€ CMakeLists.txt
    â”œâ”€â”€ CPU
    â”‚   â”œâ”€â”€ CMakeLists.txt
    â”‚   â”œâ”€â”€ QuEST_cpu.c
    â”‚   â”œâ”€â”€ QuEST_cpu_distributed.c	//distributed activator and implementation
    â”‚   â”œâ”€â”€ QuEST_cpu_internal.h		 //other cpu related headers here
    â”‚   â””â”€â”€ QuEST_cpu_local.c			   //only cpu implementation
    â”œâ”€â”€ GPU
    â”‚   â”œâ”€â”€ CMakeLists.txt
    â”‚   â””â”€â”€ QuEST_gpu.cu 					 //gpu counterpart
    â”œâ”€â”€ mt19937ar.c							  //æ¢…æ£®æ—‹è½‰ç®—æ³•-ä¼ªéšæœºæ•°çŸ©é˜µç”Ÿæˆ
    â”œâ”€â”€ mt19937ar.h
    â”œâ”€â”€ QuEST.c										//main func definition
    â”œâ”€â”€ QuEST_common.c					  //func activator defined here
    â”œâ”€â”€ QuEST_debug.h						  //debug information here
    â”œâ”€â”€ QuEST_internal.h
    â”œâ”€â”€ QuEST_qasm.c							//is a quantum record standard, defined qasm assertion here.
    â”œâ”€â”€ QuEST_qasm.h
    â”œâ”€â”€ QuEST_validation.c					//assert number of qubit here
    â””â”€â”€ QuEST_validation.h
</code></pre>
<p>https://www.quantum-inspire.com/kbase/introduction-to-quantum-computing</p>
<h2 id="testcase-analysis"><a class="header" href="#testcase-analysis">testcase analysis</a></h2>
<p><code>mytimer.hpp</code></p>
<pre><code class="language-cpp">#include &lt;time.h&gt;
#include &lt;sys/time.h&gt;
 
 double get_wall_time(){
 /* A time value that is accurate to the nearest
   microsecond but also has a range of years.  */
   struct timeval time;
 // __time_t tv_sec;		/* Seconds.  */
 // __suseconds_t tv_usec;	/* Microseconds.  */
   if (gettimeofday(&amp;time,NULL)){
     // Handle error
     return 0;
   }
 
   return (double)time.tv_sec + (double)time.tv_usec * .000001;
 }
 
 double get_cpu_time(){
   return (double)clock() / CLOCKS_PER_SEC;//directly read clock from cpu, and return with clock times cloacks per sec.
 }```
</code></pre>
<p><code>random.c</code> - random manipulation</p>
<pre><code class="language-cpp">// total number of qubit: 30
// total number of qubit operatations: 667
// estimated time: 3783.9266747315614 second.
#include &quot;QuEST.h&quot;
#include &quot;mytimer.hpp&quot;
#include &quot;stdio.h&quot;

int main(int narg, char *argv[])
{

    QuESTEnv Env = createQuESTEnv();
    double t1 = get_wall_time();//define starting time 

    FILE *fp = fopen(&quot;probs.dat&quot;, &quot;w&quot;);//open file for result
    if (fp == NULL) {
        printf(&quot;    open probs.dat failed, Bye!&quot;);
        return 0;
    }

    FILE *fvec = fopen(&quot;stateVector.dat&quot;, &quot;w&quot;);
    if (fp == NULL) {
        printf(&quot;    open stateVector.dat failed, Bye!&quot;);
        return 0;
    }

    Qureg q =  createQureg(30, Env);//define qubits registers

    float q_measure[30];// defined q's size
   // possible execution.
    tGate(q, 25);
    controlledNot(q, 28, 21);
    controlledRotateX(q, 17, 5, 0.3293660327520663);
    tGate(q, 3);
    rotateX(q, 10, 4.734238389048838);
    rotateY(q, 8, 4.959946047271496);
    rotateZ(q, 5, 1.0427019597472071);
    pauliZ(q, 0);
	...
        
    printf(&quot;\n&quot;);
    for (long long int i = 0; i &lt; 30; ++i) {
        q_measure[i] = calcProbOfOutcome(q, i, 1);
        printf(&quot;  probability for q[%2lld]==1 : %lf    \n&quot;, i, q_measure[i]);
        fprintf(fp, &quot;Probability for q[%2lld]==1 : %lf    \n&quot;, i, q_measure[i]);
    }
    fprintf(fp, &quot;\n&quot;);
    printf(&quot;\n&quot;);

    for (int i = 0; i &lt; 10; ++i) {
        Complex amp = getAmp(q, i);
        printf(&quot;Amplitude of %dth state vector: %12.6f,%12.6f\n&quot;, i, amp.real,
               amp.imag);
    }

    double t2 = get_wall_time();
    printf(&quot;Complete the simulation takes time %12.6f seconds.&quot;, t2 - t1);
    printf(&quot;\n&quot;);
    destroyQureg(q, Env);
    destroyQuESTEnv(Env);

    return 0;
}
</code></pre>
<p><code>GHZ_QFT.c</code> - only controlled manipulation</p>
<pre><code class="language-cpp">/* GHZ quantum circuit */
    hadamard(q, 0);
    controlledNot(q, 0, 1);
    controlledNot(q, 1, 2);
    controlledNot(q, 2, 3);
    controlledNot(q, 3, 4);
    controlledNot(q, 4, 5);
    controlledNot(q, 5, 6);
    controlledNot(q, 6, 7);
    controlledNot(q, 7, 8);
    controlledNot(q, 8, 9);
    controlledNot(q, 9, 10);
    controlledNot(q, 10, 11);
    controlledNot(q, 11, 12);
    controlledNot(q, 12, 13);
    controlledNot(q, 13, 14);
    controlledNot(q, 14, 15);
    controlledNot(q, 15, 16);
    controlledNot(q, 16, 17);
    controlledNot(q, 17, 18);
    controlledNot(q, 18, 19);
    controlledNot(q, 19, 20);
    controlledNot(q, 20, 21);
    controlledNot(q, 21, 22);
    controlledNot(q, 22, 23);
    controlledNot(q, 23, 24);
    controlledNot(q, 24, 25);
    controlledNot(q, 25, 26);
    controlledNot(q, 26, 27);
    controlledNot(q, 27, 28);
    controlledNot(q, 28, 29);
	/* end of GHZ circuit */

	/* QFT starts */
    hadamard(q, 0);
    controlledRotateZ(q, 0, 1, 1.5708);
    hadamard(q, 1);
    controlledRotateZ(q, 0, 2, 0.785398);
    controlledRotateZ(q, 1, 2, 1.5708);
    hadamard(q, 2);
    controlledRotateZ(q, 0, 3, 0.392699);
    controlledRotateZ(q, 1, 3, 0.785398);
    controlledRotateZ(q, 2, 3, 1.5708);
    ...
</code></pre>
<h2 id="available-test-machine"><a class="header" href="#available-test-machine">available test machine</a></h2>
<ol>
<li>
<p>2node 16core each <code>mpi:omp=2:16</code></p>
<pre><code class="language-bash">#!/bin/sh
module purge
spack load intel ##openmpi@3.1.5/3.1.2
export PRECISION=4 ##1/2/4
CC=icc CXX=icpc cmake -DGPUACCELERATED=0 -DDISTRIBUTED=1 ..
make
export OMP_NUM_THREADS=16
export FI_PROVIDER=tcp
mpirun -machinefile mac -np 2 ./demo 
</code></pre>
<p>profiling result</p>
<p><img src="Apps/ASC/asc-20/image-20200206174728724.png" alt="" /></p>
<p><img src="Apps/ASC/asc-20/image-20200206174748013.png" alt="" /></p>
<p>the most time-consuming part is statevec_compactUnitaryLocal</p>
</li>
<li>
<p>2node 16core each <code>mpi:omp=1:32</code></p>
<img src="https://www.victoryang00.cn/picture/image-20200206180552841.png" alt="image-20200206180552841" style="zoom:33%;" />
</li>
<li>
<p>1node 1tesla v100</p>
<p>script</p>
<pre><code class="language-bash">#!/bin/sh
module purge
spack load gcc@6
spack load cuda@10.1 ## 10.2
export PATH=$PATH:/usr/local/cuda/bin
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64
export LIBRARY_PATH=$LIBRARY_PATH:/usr/local/cuda/lib64

export PRECISION=2 ##1/2
CC=gcc CXX=g++ cmake -DGPUACCELERATED=1 -DGPU_COMPUTE_CAPABILIty=70 ..
make
./demo 
</code></pre>
<p>profiling result</p>
<p><img src="Apps/ASC/asc-20/image-20200206200505308.png" alt="" /></p>
</li>
</ol>
<p>summary</p>
<img src="https://www.victoryang00.cn/picture/image-20200206200701826.png" alt="image-20200206200701826" style="zoom:50%;" />
<p><img src="Apps/ASC/asc-20/image-20200206202701475.png" alt="" /></p>
<p>the summary for profiling of both cpu and gpu, the most time is consumed on computing the real kernel which I think the computing power is fully utilized. </p>
<p>Accelerated percentage of single node over omp+mpi is 319.799/220.807=1.448319120317744â€¬â€¬</p>
<p>Accelerated percentage of single node over single gpu is 319.799/19.328=16.54627720533642</p>
<p>power consumption: over cpu:<img src="https://www.victoryang00.cn/picture/image-20200206203642478.png" alt="image-20200206203642478" style="zoom:25%;" /></p>
<p>â€‹									over gpu: 111W on average</p>
<p>Our future plan: </p>
<ol>
<li>deploy the gpu code on multigpu using nccl.</li>
<li>solve the global memory store and load efficiency.</li>
</ol>
<h2 id="misc"><a class="header" href="#misc">misc</a></h2>
<p>Loves from Github</p>
<ol>
<li>https://github.com/QuEST-Kit/QuEST/issues/220
<img src="Apps/ASC/asc-20/image-20200206203018990.png" alt="" /></li>
</ol>
<pre><code>Hi Jiachen,

There are no plans currently to combine distribution with GPU-acceleration. Note there are a few ways this can be done, and I suspect none really align with QuEST's design philosophy, nor are practical due to memory overheads. I've wanted to pen these thoughts for a while, so read on below if interested! :)

Firstly, QuEST uses its hardware to accelerate the simulation of a single quantum register at a time. While I think there are good uses of multi-GPU to speedup simultaneous simulation of multiple registers, this would be a totally new pattern to QuEST's simulation style. So let's consider using multi-GPU to accelerate a single register.

There are a few ways you can have &quot;multiple GPUs&quot;:

multiple NVlinked GPUs
This is when you have multiple GPUs tightly connected with a high-bandwidth fabric (e.g. this). The bandwidth is enough that you sort of can imagine it as a single big GPU, and hence it would be worthwhile for accelerating single-register simulation. However, this only exists right now as NVLink and NVSwitch, compatible only with IBM's POWER architecture - you could argue this is still esoteric, and not worth a big refactor. Note it wouldn't actually be very hard to refactor QuEST for this platform - indeed QuEST works out-of-the-box with POWER8. But it's not something on our TODO list currently.

multiple local GPUs
This is when you have multiple GPUs on the same machine, but maybe on different sockets and hence with a much lower bandwidth between them. The most common case is two GPUs - is it worthwhile using two GPUs over one to speedup single register simulation? Often, no!
In big QC simulation, having to move memory around is often the big killer, and should be avoided where possible. Unfortunately, simulating unitaries on registers often requires moving memory. If all the memory stays in the GPU (very high &quot;internal bandwidth&quot;), this is ok, but copying memory to the other GPU (across the socket) will introduce a huge per-gate overhead!
Hence, using two GPUs to simulate the same register size can be slower than using just one, especially as the simulation size grows and saturates the sockets!
There's hardly a benefit from the extra VRAM too, because doubling the memory enables simulation of one additional qubit. This is not worth the slowdown, or the hardware!
Even with more than two GPUs, the connections are likely hierarchical and so even more prone to saturation.

distributed GPUs
This is when you have a GPU(s) on each distributed node of a cluster. In this circumstance, simulating a unitary gate which requires data exchange not only costs us a VRAM to RAM overhead (similar to before), but a networking overhead to talk to the other nodes! This can be somewhat improved by having a direct GPU to network-card connection (and MPI abstraction), but I believe that's pretty cutting-edge.
Let's say you have n nodes, each with a GPU and a multicore CPU, and you're resolved to a distributed simulation. When is it worthwhile to pay the extra memory overhead locally copying from RAM to VRAM (and use the GPU), over using just the CPUs? This is now the same trade-off to consider in the previous cases. So may or may not be worthwhile.

TL-DR: besides the somewhat esoteric case of having multiple tightly-connected GPUs, multi-GPU simulation introduces a new memory overhead that doesn't exist in single-GPU simulation. This overhead is almost always way longer than the time the GPU spends simulating the gate. As to whether the whole simulation is sped up by the use of multi-GPU is system and simulation specific.
</code></pre>
<ol start="2">
<li>https://github.com/NVIDIA/nccl/pull/316
This is a PR for people to review and provide feedback on the p2p branch (issue <a href="https://github.com/NVIDIA/nccl/issues/212">#212</a>).</li>
</ol>
<pre><code>Looking forward to applying the P2P function to increase the power of my project!
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="isc"><a class="header" href="#isc">ISC</a></h1>
<h2 id="å¥–é¡¹"><a class="header" href="#å¥–é¡¹">å¥–é¡¹</a></h2>
<ul>
<li>æ€»å† å†›ä¸€åï¼Œæˆäºˆåœ¨æ•´ä½“ç®—ä¾‹ä»¥åŠç°åœºå‘ˆç°è¿‡ç¨‹ä¸­å¾—åˆ†æœ€é«˜çš„é˜Ÿä¼ã€‚</li>
<li>HPLå•é¡¹å† å†›ä¸€åï¼ŒæˆäºˆHPLæ¯”èµ›æˆç»©æœ€é«˜çš„é˜Ÿä¼ã€‚</li>
<li>æœ€å—æ¬¢è¿å¥–ä¸€åï¼Œæˆäºˆæ¯”èµ›æœŸé—´å¾—åˆ°ISC13å‚ä¼šè€…æŠ•ç¥¨æœ€å¤šçš„é˜Ÿä¼ã€‚</li>
</ul>
<h2 id="å‘½é¢˜"><a class="header" href="#å‘½é¢˜">å‘½é¢˜</a></h2>
<p>HPLç­‰benchmarkå’Œå…¶ä»–4é¡¹åº”ç”¨ä»¥åŠä¸€é“ç¥ç§˜èµ›é¢˜ã€‚</p>
<div style="break-before: page; page-break-before: always;"></div><p>å¤±è´¥äº†</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="autotuning-å°±æ˜¯ä¸€ä¸ªç®€å•oié¢˜"><a class="header" href="#autotuning-å°±æ˜¯ä¸€ä¸ªç®€å•oié¢˜">AutoTuning å°±æ˜¯ä¸€ä¸ªç®€å•OIé¢˜</a></h2>
<p>é¢˜ç›®è¦æ±‚æ ¹æ®ä¸åŒ rank ä¹‹é—´çš„æ•°æ®äº¤æ¢èƒ½åŠ›ï¼Œåšç®€å•çš„è°ƒä¼˜ï¼Œè€Œæ•´ä¸ª</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="wrf"><a class="header" href="#wrf">WRF</a></h1>
<blockquote>
<p>å‚»é€¼Fortranï¼Œ2021å¹´äº†ï¼Œå±…ç„¶è¿˜æœ‰äººç”¨Fortran</p>
<p>æœ€å¥½æ‰¾åšæ°”è±¡çš„äººé—®é—®æœ‰å…³å‚æ•°è®¾ç½®çš„é—®é¢˜ï¼Œå¯æƒœæˆ‘æ²¡æ‰¾åˆ°</p>
</blockquote>
<p>è¿™æ˜¯ä¸€ä¸ªæœ‰å…³åœ°çƒç§‘å­¦çš„å¤©æ°”æ¨¡æ‹Ÿç³»ç»Ÿï¼Œæ‰€æœ‰æœ‰å…³åœ°çƒç§‘å­¦å’ŒFortranå¹¶è¡ŒåŒ–çš„å…¶ä»–åº”ç”¨éƒ½å¯ä»¥å‚è€ƒä¸€ä¸‹</p>
<h2 id="task-links-and-introductions"><a class="header" href="#task-links-and-introductions">Task links and introductions</a></h2>
<p><a href="https://hpcadvisorycouncil.atlassian.net/wiki/spaces/HPCWORKS/pages/1827438600/WRF+with+Single+Domain+-+Practice+case+for+ISC21+SCC">Practice case for ISC21 SCC</a></p>
<p><a href="https://hpcadvisorycouncil.atlassian.net/wiki/spaces/HPCWORKS/pages/1827438607/WRF+-+3+Domain+Problem+for+ISC21+SCC">3 Domain Problem for ISC21 SCC</a></p>
<h2 id="install"><a class="header" href="#install">Install</a></h2>
<h3 id="required-libs"><a class="header" href="#required-libs">required libs</a></h3>
<p>HDF5, NetCDF-C, NetCDF-Fortran (æ‰‹åŠ¨å®‰è£…å¯èƒ½æ›´å¥½ï¼Œéœ€è¦mpi)</p>
<h4 id="hdf5"><a class="header" href="#hdf5">HDF5</a></h4>
<pre><code class="language-bash">./configure --prefix=ä½ çš„å®‰è£…è·¯å¾„/hdf5 --enable-fortran --enable-fortran2003 --enable-parallel
make -j 48
make install
</code></pre>
<pre><code class="language-bash"># vi ~/.bashrc
export HDF5=ä½ çš„å®‰è£…è·¯å¾„/hdf5
export PATH=$HDF5/bin:$PATH
export LD_LIBRARY_PATH=$HDF5/lib:$LD_LIBRARY_PATH
export INCLUDE=$HDF5/include:$INCLUDE
# source ~/.bashrc
</code></pre>
<h4 id="netcdf-c"><a class="header" href="#netcdf-c">NetCDF-C</a></h4>
<pre><code class="language-bash">./configure --prefix=ä½ çš„å®‰è£…è·¯å¾„/netcdf LDFLAGS=&quot;-L$HDF5/lib&quot; CPPFLAGS=&quot;-I$HDF5/include&quot; CC=mpiicc --disable-dap
make -j 48
make install
</code></pre>
<pre><code class="language-bash"># vi ~/.bashrc
export NETCDF=/usr/local/netcdf
export PATH=$NETCDF/bin:$PATH
export LD_LIBRARY_PATH=$NETCDF/lib:$LD_LIBRARY_PATH
export INCLUDE=$NETCDF/include:$INCLUDE
# source ~/.bashrc
</code></pre>
<h4 id="netcdf-fortran"><a class="header" href="#netcdf-fortran">NetCDF-Fortran</a></h4>
<pre><code class="language-bash">./configure --prefix=ä½ çš„å®‰è£…è·¯å¾„/netcdf CPPFLAGS=&quot;-I$HDF5/include -I$NETCDF/include&quot; LDFLAGS=&quot;-L$HDF5/lib -L$NETCDF/lib&quot; CC=mpiicc FC=mpiif90 F77=mpiif90 # ä¸NetCDF-Cå®‰è£…åœ¨åŒä¸€ç›®å½•ä¸‹
make -j 48
make install
</code></pre>
<h3 id="advanced-lib"><a class="header" href="#advanced-lib">Advanced lib</a></h3>
<p><a href="https://parallel-netcdf.github.io/">PNetCDF</a> A Parallel I/O Library for NetCDF File Access</p>
<blockquote>
<p>4ä¸ªnodeæœ‰è´Ÿé¢æ•ˆæœï¼Œéœ€è¦8ä¸ªnodeåŠä»¥ä¸Šæ‰ä¼šå’ŒNertCDFæœ‰å¼‚</p>
</blockquote>
<p><a href="https://z3.ax1x.com/2021/07/15/WnELTI.md.png">pnetcdf.png</a></p>
<p>å®‰è£…æ–¹æ³•è§å®˜ç½‘</p>
<h3 id="main-program"><a class="header" href="#main-program">Main Program</a></h3>
<p>ç»è¿‡æµ‹è¯•ï¼Œä½¿ç”¨intelMPIä¼šå‡ºç°segment faultï¼ŒOpenMPIåˆ™ä¸ä¼šï¼Œç„¶è€ŒintelMPIå¥½åƒå¹¶æ²¡æœ‰å¾ˆå¤šæé«˜ï¼Œå¯ä»¥ä»stack sizeçš„è§’åº¦å°è¯•ä¿®æ­£è¿™ä¸ªé—®é¢˜ã€‚</p>
<h4 id="env-setting"><a class="header" href="#env-setting">env setting</a></h4>
<pre><code class="language-bash">intel openmpi hdf5 netcdf
</code></pre>
<h4 id="config-and-build"><a class="header" href="#config-and-build">config and build</a></h4>
<pre><code class="language-bash">./configure
</code></pre>
<pre><code class="language-bash">checking for perl5... no
checking for perl... found /usr/bin/perl (perl)
Will use NETCDF in dir: /global/software/centos-7.x86_64/modules/intel/2020.1.217/netcdf/4.7.4
HDF5 not set in environment. Will configure WRF for use without.
PHDF5 not set in environment. Will configure WRF for use without.
Will use 'time' to report timing information
$JASPERLIB or $JASPERINC not found in environment, configuring to build without grib2 I/O...
------------------------------------------------------------------------
Please select from among the following Linux x86_64 options:

  1. (serial)   2. (smpar)   3. (dmpar)   4. (dm+sm)   PGI (pgf90/gcc)
  5. (serial)   6. (smpar)   7. (dmpar)   8. (dm+sm)   PGI (pgf90/pgcc): SGI MPT
  9. (serial)  10. (smpar)  11. (dmpar)  12. (dm+sm)   PGI (pgf90/gcc): PGI accelerator
 13. (serial)  14. (smpar)  15. (dmpar)  16. (dm+sm)   INTEL (ifort/icc)
                                         17. (dm+sm)   INTEL (ifort/icc): Xeon Phi (MIC architecture)
 18. (serial)  19. (smpar)  20. (dmpar)  21. (dm+sm)   INTEL (ifort/icc): Xeon (SNB with AVX mods)
 22. (serial)  23. (smpar)  24. (dmpar)  25. (dm+sm)   INTEL (ifort/icc): SGI MPT
 26. (serial)  27. (smpar)  28. (dmpar)  29. (dm+sm)   INTEL (ifort/icc): IBM POE
 30. (serial)               31. (dmpar)                PATHSCALE (pathf90/pathcc)
 32. (serial)  33. (smpar)  34. (dmpar)  35. (dm+sm)   GNU (gfortran/gcc)
 36. (serial)  37. (smpar)  38. (dmpar)  39. (dm+sm)   IBM (xlf90_r/cc_r)
 40. (serial)  41. (smpar)  42. (dmpar)  43. (dm+sm)   PGI (ftn/gcc): Cray XC CLE
 44. (serial)  45. (smpar)  46. (dmpar)  47. (dm+sm)   CRAY CCE (ftn $(NOOMP)/cc): Cray XE and XC
 48. (serial)  49. (smpar)  50. (dmpar)  51. (dm+sm)   INTEL (ftn/icc): Cray XC
 52. (serial)  53. (smpar)  54. (dmpar)  55. (dm+sm)   PGI (pgf90/pgcc)
 56. (serial)  57. (smpar)  58. (dmpar)  59. (dm+sm)   PGI (pgf90/gcc): -f90=pgf90
 60. (serial)  61. (smpar)  62. (dmpar)  63. (dm+sm)   PGI (pgf90/pgcc): -f90=pgf90
 64. (serial)  65. (smpar)  66. (dmpar)  67. (dm+sm)   INTEL (ifort/icc): HSW/BDW
 68. (serial)  69. (smpar)  70. (dmpar)  71. (dm+sm)   INTEL (ifort/icc): KNL MIC
 72. (serial)  73. (smpar)  74. (dmpar)  75. (dm+sm)   FUJITSU (frtpx/fccpx): FX10/FX100 SPARC64 IXfx/Xlfx

Enter selection [1-75] :
</code></pre>
<p>dm+sm: OMP+MPI</p>
<pre><code class="language-bash">./compile -j 6 em_real &gt;&amp; build_wrf.log
tail -15 build_wrf.log
</code></pre>
<h4 id="finish"><a class="header" href="#finish">finish</a></h4>
<p>æ‰€æœ‰æ‰§è¡Œæ–‡ä»¶éƒ½åœ¨<code>run</code>æ–‡ä»¶å¤¹ä¸­ã€‚</p>
<h2 id="run"><a class="header" href="#run">Run</a></h2>
<pre><code class="language-bash">for i in ../WRF/run/* ; do ln -sf $i $(æ•°æ®æ‰€åœ¨ç›®å½•) ; done
</code></pre>
<p><code>namelist.input</code>æ˜¯è¾“å…¥æ–‡ä»¶ï¼Œå…¶ä¸­æœ‰ä¼—å¤šå‚æ•°éœ€è¦è®¾ç½®ï¼Œå¯ä»¥å‚è€ƒ<a href="https://esrl.noaa.gov/gsd/wrfportal/namelist_input_options.html"><strong>WRF NAMELIST.INPUT FILE DESCRIPTION</strong></a>ã€‚</p>
<h3 id="slurm-script"><a class="header" href="#slurm-script">slurm script</a></h3>
<pre><code class="language-bash">#!/bin/bash -l
#SBATCH -N 4
#SBATCH --ntasks-per-node=20
#SBATCH --cpus-per-task=2
#SBATCH --ntasks=80
#SBATCH -J wrf3Dom_mpi_80_omp_2
#SBATCH -p compute
#SBATCH -t 2:00:00
#SBATCH -o wrf3Dom-%j.out
sleep 300
module load NiaEnv/2019b
module load intel/2019u4  openmpi/4.0.1
#hdf5/1.10.5
#module load netcdf/4.6.3

ulimit -c unlimited
ulimit -s unlimited

module list

export HDF5=/home/l/lcl_uotiscscc/lcl_uotiscsccs1034/scratch/nonspack/hdf5
export PATH=$HDF5/bin:$PATH
export LD_LIBRARY_PATH=$HDF5/lib:$LD_LIBRARY_PATH
export INCLUDE=$HDF5/include:$INCLUDE

export NETCDF=/home/l/lcl_uotiscscc/lcl_uotiscsccs1034/scratch/nonspack/netcdf
export PATH=$NETCDF/bin:$PATH
export LD_LIBRARY_PATH=$NETCDF/lib:$LD_LIBRARY_PATH
export INCLUDE=$NETCDF/include:$INCLUDE


export KMP_STACKSIZE=20480000000


export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK
cd ~/scratch/pl/orifiles
mpirun -np 80 -cpus-per-rank $SLURM_CPUS_PER_TASK ./wrf.exe
</code></pre>
<h2 id="important-notice"><a class="header" href="#important-notice">Important Notice</a></h2>
<h3 id="stack-size-and-segment-fault"><a class="header" href="#stack-size-and-segment-fault"><code>stack size</code> and <code>segment fault</code></a></h3>
<p><code>ulimit</code> sets the OS limits for the program.
<code>KMP_STACKSIZE</code> tells the OpenMP implementation about how much stack to actually allocate for each of the stacks. So, depending on your OS defaults you might need both. BTW, you should rather use <code>OMP_STACKSIZE</code> instead, as <code>KMP_STACKSIZE</code> is the environment variable used by the Intel and clang compilers. <code>OMP_STACKSIZE</code> is the standard way of setting the stack size of the OpenMP threads.
Note, that this problem is usually more exposed, as Fortran tends to keep more data on the stack, esp. arrays. Some compilers can move such arrays to the heap automatically, see for instance <code>-heap-arrays</code> for the Intel compiler.</p>
<p>Fortrançš„OMPè¿›ç¨‹ä¼šåœ¨stacké‡Œå¡ä¸€å¤§å †ä¸œè¥¿ï¼Œå¾ˆå¤šæ—¶å€™ä¼šçˆ†æ ˆï¼Œæ‰€ä»¥ä½¿ç”¨Fortranå’ŒOMPçš„åº”ç”¨éœ€è¦æ³¨æ„<code>export KMP_STACKSIZE=20480000000</code>, è€Œä¸”<code>gcc</code>æ˜¯<code>OMP</code>,<code>icc</code>æ˜¯<code>KMP</code>ã€‚</p>
<h3 id="fortran-and-mpi"><a class="header" href="#fortran-and-mpi">Fortran and MPI</a></h3>
<p>ä¸çŸ¥é“æ˜¯slurmè¿˜æ˜¯Fortrançš„é—®é¢˜ï¼Œslurmä¸èƒ½å¯¹Fortrançš„MPIç¨‹åºè‡ªåŠ¨åˆ†é…CPUæ ¸å¿ƒï¼Œæ‰€ä»¥éœ€è¦æ‰‹åŠ¨è®¾ç½®ï¼Œ</p>
<pre><code class="language-bash">mpirun -np 16 -cpus-per-rank $SLURM_CPUS_PER_TASK ./wrf.exe
</code></pre>
<p>tell mpi how many cpu cores should one mpi rank get for openmp</p>
<h3 id="ipm-report-env-setting"><a class="header" href="#ipm-report-env-setting">IPM Report env setting</a></h3>
<p>IPMæ˜¯ä¸€ä¸ªç›‘æ§MPIä½¿ç”¨çš„profilerã€‚ä½¿ç”¨IPMåªéœ€è¦perloadIPMçš„libå°±å¯ä»¥äº†ã€‚ä½†æ˜¯ä¸ºäº†å®Œæ•´ç”ŸæˆæŠ¥å‘Šå›¾ç‰‡ï¼Œéœ€è¦è®¾å®šä»¥ä¸‹å˜é‡</p>
<pre><code class="language-bash">export IPM_REPORT=full
export IPM_LOG=full
</code></pre>
<p>When using IPM, set above envs to make sure you can get right xml to visualize, or using https://files.slack.com/files-pri/TAXMW9014-F02586VN27L/download/ipm.ipynb to visualize</p>
<h2 id="others"><a class="header" href="#others">Others</a></h2>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><h1 id="quantum-espresso"><a class="header" href="#quantum-espresso">Quantum Espresso</a></h1>
<p>https://github.com/QEF/q-e</p>
<h3 id="compile"><a class="header" href="#compile">compile</a></h3>
<p>Could not find MPI (Missing MPI_FORTRAN_FOUND)</p>
<p>solve:  <code>-DMPIEXEC_EXECTUABLE=${MPI_HOME}/bin/mpiexec</code></p>
<p>The compiled version does not support OpenMP and only support up to 4 processes for MPI.</p>
<p>Add the options: </p>
<p><code>-DQE_ENABLE_OPENMP=ON</code>
<code>-DCMAKE_Fortran_COMPILER=${MPI_HOME}/bin/mpifort</code>
<code>-DOpenMP_C_FLAGS=-fopenmp=lomp</code>
<code>-DOpenMP_CXX_FLAGS=-fopenmp=lomp</code>
<code>-DOpenMP_C_LIB_NAMES=libomp</code>
<code>-DOpenMP_CXXLIB_NAMES=libomp</code>
<code>-DOpenMP_libomp_LIBRARY=/usr/lib/x86_64-linux-gnu/libomp.so.5</code></p>
<p>Change Toolchain to <code>System</code>.</p>
<p>Add <code>-g</code> to <code>CMakeList.txt</code> to get additional debug information.</p>
<p><code>set(CMAKE_CXX_FLAGS -g)</code>
<code>set(CMAKE_C_FLAGS -g)</code>
<code>set(CMAKE_Fortran_FLAGS -g)</code></p>
<p>https://www.quantum-espresso.org/Doc/user_guide/</p>
<p>library configure: https://www.quantum-espresso.org/Doc/user_guide/node11.html</p>
<h3 id="test"><a class="header" href="#test">test</a></h3>
<p>In directory <code>/q-e/test-suite/</code>, use <code>make run-tests</code> to test the correctness of basic functionalities. </p>
<h3 id="run-1"><a class="header" href="#run-1">run</a></h3>
<p><code>spack load ucx/gji</code></p>
<p><code>/home/qe/q-e/bin/pw.x</code></p>
<p>To control the number of processors in each group, command line switches: -nimage, -npools, -nband, -ntg, -ndiag or -northo (shorthands, respectively: -ni, -nk, -nb, -nt, -nd) are used. As an example consider the following command line:
<code>mpirun -np 4096 ./neb.x -ni 8 -nk 2 -nt 4 -nd 144 -i my.input</code> This executes a NEB calculation on 4096 processors, 8 images (points in the configuration space in this case) at the same time, each of which is distributed across 512 processors. k-points are distributed across 2 pools of 256 processors each, 3D FFT is performed using 4 task groups (64 processors each, so the 3D real-space grid is cut into 64 slices), and the diagonalization of the subspace Hamiltonian is distributed to a square grid of 144 processors (12x12).</p>
<p><code>mpirun -np 24 -x PATH --oversubscribe -x OMP_NUM_THREADS=4 -x LD_LIBRARY_PATH=/opt/nonspack/ucx-1.10.0-gcc/lib --allow-run-as-root /home/qe/q-e/bin/pw.x &lt; ./ausurf.in</code></p>
<p>First run with 24 processes and 4 thread each: </p>
<p><img src="Apps/SC/SC21/./quantum-espresso.png" alt="" /></p>
<p>Problem: OMP threads can only use up to 200% CPU per process even with 256 threads per process. </p>
<h3 id="analyze"><a class="header" href="#analyze">Analyze</a></h3>
<h4 id="static-analysis"><a class="header" href="#static-analysis">Static Analysis</a></h4>
<p>Using lizard</p>
<p>Fortran: </p>
<pre><code>Total nloc  Avg.NLOC  AvgCCN  Avg.token  Fun Cnt  Warning cnt  Fun Rt  nloc Rt
599949      54.1      10.6    569.7      9939     1693         0.17    0.58
</code></pre>
<p>C:</p>
<pre><code>Total nloc  Avg.NLOC  AvgCCN  Avg.token  Fun Cnt  Warning cnt  Fun Rt  nloc Rt
52039       152.5     3.0     1050.3     323      19           0.06    0.53
</code></pre>
<p>Python:</p>
<pre><code>Total nloc  Avg.NLOC  AvgCCN  Avg.token  Fun Cnt  Warning cnt  Fun Rt  nloc Rt
8864        18.3      5.0     146.0      298      21           0.07    0.26
</code></pre>
<h4 id="profiling-result"><a class="header" href="#profiling-result">Profiling result</a></h4>
<p>All the GPU versionn test case seems to have IEEE underflow, trigger by the FFTlib, which should be fixed. Since the developing team of this project still aggressively develop the application to tailor to GPU. </p>
<p>We chose to use a case called si.scf.david.in to profile on single GPU. And here's the profiling result.</p>
<pre><code class="language-bash">=117847== Profiling application: /home/qe/bin/pw.x -i ./si.scf.david.in
==117847== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:    8.72%  22.118ms       140  157.98us  157.82us  159.81us  usnldiag_collinear_79_gpu
                    6.46%  16.390ms      1360  12.051us  11.840us  189.41us  init_us_2_base_gpu_216_gpu
                    5.29%  13.411ms        10  1.3411ms  1.3407ms  1.3417ms  rotate_wfc_k_gpu_146_gpu
                    4.24%  10.763ms       370  29.090us  28.704us  32.928us  ylmr2_gpum_ylmr2_gpu_kernel_
                    3.71%  9.4250ms      1127  8.3620us  6.5280us  17.664us  volta_zgemm_32x32_nn
                    3.23%  8.1880ms      1224  6.6890us  6.5920us  7.1040us  init_us_2_base_gpu_220_gpu
                    2.68%  6.8026ms       680  10.003us  9.8560us  10.784us  init_us_2_base_gpu_185_gpu
                    2.67%  6.7818ms       340  19.946us  19.744us  21.280us  init_us_2_base_gpu_206_gpu
                    2.61%  6.6090ms       340  19.438us  19.295us  21.504us  init_us_2_base_gpu_158_gpu
                    2.46%  6.2396ms       689  9.0560us  7.2000us  14.432us  void zgemm_largek_warp&lt;bool=1, bool=0, bool=1, bool=0, int=3, int=3, int=4, int=3, int=2, int=2, int=9&gt;(double2*, double2 const *, double2 const *, int, int, int, int, int, int, double2 const *, double2 const *, double2, double2, int, int, int*, int*)
                    2.28%  5.7953ms       159  36.448us  19.392us  43.200us  cegterg_gpu_493_gpu
                    2.20%  5.5704ms      1104  5.0450us  4.1600us  11.488us  void composite_2way_fft&lt;unsigned int=20, unsigned int=4, unsigned int=32, padding_t=0, twiddle_t=0, loadstore_modifier_t=2, unsigned int=5, layout_t=1, unsigned int, double&gt;(kernel_arguments_t&lt;unsigned int&gt;)
                    2.17%  5.4956ms       478  11.497us  11.359us  12.864us  add_vuspsi_k_gpu_242_gpu
                    1.98%  5.0265ms       239  21.031us  10.208us  40.384us  vloc_psi_k_gpu_464_gpu
                    1.86%  4.7254ms       219  21.577us  12.319us  33.824us  void sytd2_upper_cta&lt;double2, double, int=4&gt;(int, double2*, unsigned long, double*, double*, double2*)
                    1.71%  4.3307ms       219  19.774us  19.743us  20.960us  laxlib_cdiaghg_gpu_349_gpu
                    1.64%  4.1660ms       239  17.430us  17.248us  19.488us  vloc_psi_k_gpu_477_gpu
                    1.48%  3.7585ms         1  3.7585ms  3.7585ms  3.7585ms  force_corr_gpu_103_gpu
                    1.45%  3.6914ms       239  15.444us  15.264us  16.704us  vloc_psi_k_gpu_456_gpu
                    1.40%  3.5579ms      2320  1.5330us  1.4080us  13.056us  [CUDA memcpy DtoH]
                    1.36%  3.4570ms       219  15.785us  15.712us  16.352us  laxlib_cdiaghg_gpu_317_gpu
                    1.34%  3.4099ms       159  21.445us  21.280us  23.136us  g_psi_gpu_53_gpu
                    1.28%  3.2424ms      1979  1.6380us  1.2160us  13.120us  [CUDA memcpy HtoD]
                    1.22%  3.0915ms       552  5.6000us  4.2880us  9.0560us  void composite_2way_fft&lt;unsigned int=20, unsigned int=4, unsigned int=16, padding_t=0, twiddle_t=0, loadstore_modifier_t=2, unsigned int=5, layout_t=0, unsigned int, double&gt;(kernel_arguments_t&lt;unsigned int&gt;)
                    1.19%  3.0239ms       239  12.652us  10.816us  14.240us  h_psi__gpu_158_gpu
                    1.14%  2.8893ms       219  13.193us  9.2160us  20.192us  void trsm_ln_up_kernel&lt;double2, unsigned int=32, unsigned int=32, unsigned int=4, bool=0&gt;(int, int, double2 const *, int, double2*, int, double2, double2 const *, int, int*)
                    1.12%  2.8463ms      1095  2.5990us  2.4960us  3.2640us  copy_info_kernel(int, int*)
                    1.06%  2.6975ms       170  15.867us  15.647us  16.544us  init_us_2_base_gpu_119_gpu
                    1.02%  2.5845ms        40  64.612us  64.320us  72.960us  stres_us_k_gpu_702_gpu
                    1.01%  2.5699ms       159  16.162us  16.096us  16.704us  reorder_evals_cevecs_707_gpu
                    0.99%  2.5005ms        40  62.512us  62.240us  70.656us  stres_us_k_gpu_817_gpu
                    0.97%  2.4644ms       159  15.499us  15.232us  16.576us  cegterg_gpu_427_gpu
                    0.96%  2.4360ms        70  34.799us  34.720us  35.424us  cegterg_gpu_265_gpu
                    0.89%  2.2453ms        40  56.131us  55.840us  63.040us  stres_knl_gpu_100_gpu
                    0.86%  2.1855ms        40  54.636us  54.463us  56.832us  stres_us_k_gpu_543_gpu
                    0.82%  2.0773ms       243  8.5480us  7.2320us  11.904us  fft_scalar_cufft_cfft3d_gpu_586_gpu
                    0.82%  2.0749ms       280  7.4100us  7.3280us  7.8720us  get_rho_gpu_954_gpu
                    0.80%  2.0350ms       212  9.5990us  9.4080us  10.016us  dp_dev_memcpy_c2d_770_gpu
                    0.71%  1.7922ms       689  2.6010us  2.4960us  3.7440us  void scal_kernel&lt;double2, double2, int=1, bool=1, int=5, int=4, int=4, int=4&gt;(cublasTransposeParams&lt;double2&gt;, double2 const *, double2*, double2 const *)
                    0.70%  1.7640ms       159  11.094us  10.912us  11.744us  cegterg_gpu_376_gpu
                    0.67%  1.7032ms       508  3.3520us  3.1670us  4.4480us  void reduce_1Block_kernel&lt;double, int=128, int=7, cublasGemvTensorStridedBatched&lt;double&gt;, cublasGemvTensorStridedBatched&lt;double&gt;, cublasGemvTensorStridedBatched&lt;double&gt;&gt;(double const *, double, double, int, double const *, double, cublasGemvTensorStridedBatched&lt;double&gt;, cublasGemvTensorStridedBatched&lt;double&gt;, cublasPointerMode_t, cublasLtEpilogue_t, cublasGemvTensorStridedBatched&lt;biasType&lt;cublasGemvTensorStridedBatched&lt;double&gt;::value_type, double&gt;::type const &gt;)
                    0.67%  1.7000ms       508  3.3460us  3.1680us  4.8640us  void dot_kernel&lt;double, int=128, int=0, cublasDotParams&lt;cublasGemvTensor&lt;double const &gt;, cublasGemvTensorStridedBatched&lt;double&gt;&gt;&gt;(double const )
                    0.66%  1.6738ms        40  41.843us  41.760us  42.944us  stres_us_k_gpu_617_gpu
                    0.66%  1.6658ms       159  10.476us  10.432us  11.136us  reorder_evals_cevecs_700_gpu
                    0.54%  1.3789ms       219  6.2960us  5.1840us  8.9280us  void potrf_alg2_cta_upper&lt;double2, double, int=32&gt;(int, int, double2*, unsigned long, int*)
                    0.53%  1.3506ms       170  7.9440us  7.8400us  8.6080us  init_us_2_base_gpu_134_gpu
                    0.53%  1.3341ms       438  3.0450us  2.4960us  188.80us  void lapack_identity_kernel&lt;double, int=8&gt;(int, int, double*, int)
                    0.52%  1.3279ms       219  6.0630us  5.0880us  8.6400us  void trsm_right_kernel&lt;double2, int=256, int=4, bool=0, bool=0, bool=0, bool=1, bool=0&gt;(cublasTrsmParams&lt;double2&gt;, double2, double2 const *, int)
                    0.52%  1.3185ms       219  6.0200us  4.3200us  8.2880us  void ormql_cta_kernel&lt;double2, int=4, int=1&gt;(int, int, int, double2 const *, unsigned long, double2 const *, double2*, unsigned long, int, int, int, int)
                    0.52%  1.3185ms        90  14.649us  14.496us  15.072us  dylmr2_gpu_78_gpu
                    0.51%  1.2925ms       209  6.1840us  6.1440us  6.4640us  dp_dev_memcpy_r1d_270_gpu
                    0.50%  1.2803ms        71  18.033us  17.983us  18.687us  cegterg_gpu_615_gpu
                    0.50%  1.2592ms       438  2.8740us  2.7200us  3.8720us  void kernel_extract_uplo_A&lt;double2, int=5, int=3&gt;(int, double2 const *, unsigned long, double2*, unsigned long, int)
                    0.50%  1.2586ms       163  7.7210us  7.5840us  8.0000us  dp_dev_memset_c2d_1851_gpu
                    0.47%  1.1830ms       408  2.8990us  2.4960us  3.7440us  __pgi_dev_cumemset_16n
                    0.47%  1.1818ms        80  14.772us  14.496us  17.216us  g2_kin_gpu_40_gpu
                    0.44%  1.1150ms       169  6.5970us  5.6960us  9.1200us  void trsm_left_kernel&lt;double2, int=256, int=4, bool=0, bool=1, bool=1, bool=1, bool=0&gt;(cublasTrsmParams&lt;double2&gt;, double2, double2 const *, int)
                    0.42%  1.0619ms        52  20.420us  18.944us  27.136us  volta_zgemm_32x32_cn
                    0.42%  1.0610ms        70  15.157us  15.104us  16.032us  sum_band_k_gpu_837_gpu
                    0.40%  1.0224ms       219  4.6680us  4.2240us  5.4720us  void lansy_M_stage1&lt;double2, double, int=8&gt;(int, double2 const *, unsigned long, double*, int)
                    0.40%  1.0046ms        90  11.162us  11.040us  11.488us  dylmr2_gpu_90_gpu
                    0.39%  984.57us        80  12.307us  12.223us  12.928us  atomic_wfc___gpu_396_gpu
                    0.37%  946.72us        80  11.833us  11.744us  12.224us  compute_deff_gpu_41_gpu
                    0.36%  909.82us       689  1.3200us  1.2480us  2.0160us  [CUDA memset]
                    0.34%  856.35us       219  3.9100us  3.8080us  5.6000us  void batch_symmetrize_kernel&lt;double2, int=5, int=3&gt;(int, double2*, unsigned long, __int64, int, int)
                    0.34%  855.00us        30  28.500us  28.352us  29.568us  gen_us_dy_gpu_229_gpu
                    0.33%  842.37us        90  9.3590us  9.2480us  9.8240us  dylmr2_gpu_101_gpu
                    0.33%  827.00us        90  9.1880us  9.0230us  10.048us  dylmr2_gpu_60_gpu
                    0.30%  772.22us       219  3.5260us  3.4870us  4.8000us  void lansy_M_stage2&lt;double, int=8&gt;(int, double*)
                    0.29%  745.95us        30  24.865us  24.831us  25.120us  gen_us_dy_gpu_198_gpu
                    0.28%  703.80us        30  23.460us  23.423us  24.128us  gen_us_dy_gpu_146_gpu
                    0.27%  690.78us       219  3.1540us  3.0720us  3.7120us  void lapack_lacpy_kernel&lt;double, int=8&gt;(int, int, double const *, int, double*, int, int, int)
                    0.27%  685.82us       219  3.1310us  3.0390us  3.6480us  void laed0_phase1_kernel&lt;double, int=8&gt;(int, double const *, int, int const *, double*, int, int, int)
                    0.25%  644.64us       219  2.9430us  2.8800us  3.9040us  void stedcx_convert_kernel&lt;double2, double, int=8&gt;(int, int, double const *, int, double2*, int)
                    0.25%  642.30us       219  2.9320us  2.8800us  3.2960us  void lacpy_kernel&lt;double2, double2, int=5, int=3&gt;(int, int, double2 const *, unsigned long, double2*, unsigned long, int, int)
                    0.25%  623.36us       219  2.8460us  2.8150us  3.2000us  potrf_alg2_reset_info(int*)
                    0.24%  598.37us       219  2.7320us  2.6880us  2.8800us  dtrsv_init_up(int*, int)
                    0.24%  596.93us       219  2.7250us  2.6880us  3.2320us  potrf_alg2_set_info(int, int, int*)
                    0.22%  558.62us        30  18.620us  18.432us  18.911us  gen_us_dy_gpu_85_gpu
                    0.21%  525.28us        70  7.5030us  7.4560us  7.6160us  diag_bands_k_693_gpu
                    0.18%  457.21us        30  15.240us  15.136us  15.968us  force_us_gpu_104_gpu
                    0.18%  456.89us        50  9.1370us  8.9910us  14.144us  void trsm_lt_up_kernel&lt;double2, unsigned int=32, unsigned int=32, unsigned int=4, bool=0, bool=1&gt;(int, int, double2 const *, int, double2*, int, double2, double2 const *, int, int*)
                    0.18%  454.24us        30  15.141us  15.040us  17.024us  gen_us_dy_gpu_185_gpu
                    0.18%  453.47us        70  6.4780us  6.4320us  6.7520us  dp_dev_memset_r2d_1431_gpu
                    0.17%  437.12us        20  21.856us  21.632us  23.712us  atomic_wfc_gpu_108_gpu
                    0.17%  427.58us        20  21.379us  20.992us  23.104us  interp_atwfc_gpu_30_gpu
                    0.15%  381.34us        30  12.711us  12.608us  13.184us  gen_us_dy_gpu_102_gpu
                    0.14%  362.69us        60  6.0440us  5.9510us  6.2720us  gen_us_dy_gpu_220_gpu
                    0.13%  334.53us        78  4.2880us  3.9040us  5.5360us  void gemv2N_kernel&lt;int, int, double2, double2, double2, double2, int=128, int=16, int=4, int=4, int=1, bool=0, cublasGemvParams&lt;cublasGemvTensorStridedBatched&lt;double2 const &gt;, cublasGemvTensorStridedBatched&lt;double2 const &gt;, cublasGemvTensorStridedBatched&lt;double2&gt;, double2&gt;&gt;(double2 const )
                    0.12%  298.91us         1  298.91us  298.91us  298.91us  compute_dvloc_gpum_compute_dvloc_gpu_
                    0.10%  255.07us        10  25.507us  25.280us  27.392us  gen_us_dj_gpu_206_gpu
                    0.10%  248.74us        10  24.873us  24.800us  25.216us  gen_us_dj_gpu_173_gpu
                    0.10%  243.93us        10  24.393us  24.256us  25.440us  gen_us_dj_gpu_119_gpu
                    0.08%  204.67us        30  6.8220us  6.7520us  6.9760us  gen_us_dy_gpu_112_gpu
                    0.08%  198.24us        52  3.8120us  3.5520us  4.9280us  void splitKreduce_kernel&lt;double2, double2, double2, double2&gt;(cublasSplitKParams&lt;double2&gt;, double2 const *, double2 const *, double2*, double2 const *, double2 const *, double2 const *)
                    0.08%  197.82us        52  3.8040us  3.6480us  4.7040us  void gemvNSP_kernel&lt;double2, double2, double2, double2, int=1, int=32, int=4, int=1024, cublasGemvParams&lt;cublasGemvTensorStridedBatched&lt;double2 const &gt;, cublasGemvTensorStridedBatched&lt;double2 const &gt;, cublasGemvTensorStridedBatched&lt;double2&gt;, double2&gt;&gt;(double2 const )
                    0.08%  194.37us        10  19.436us  19.072us  20.832us  init_wfc_gpu_295_gpu
                    0.07%  186.46us        10  18.646us  18.592us  18.816us  gen_us_dj_gpu_73_gpu
                    0.07%  182.18us        10  18.217us  18.176us  18.399us  stres_knl_gpu_84_gpu
                    0.07%  173.02us        20  8.6510us  8.6400us  8.8320us  cegterg_gpu_288_gpu
                    0.07%  172.42us        20  8.6200us  8.5120us  9.0560us  stres_us_gpu_131_gpu
                    0.07%  171.01us        10  17.100us  17.024us  17.376us  atomic_wfc_gpu_70_gpu
                    0.06%  152.13us        10  15.212us  15.071us  16.384us  gen_us_dj_gpu_160_gpu
                    0.05%  137.73us        50  2.7540us  2.7200us  2.9760us  dtrsv_init(int*)
                    0.05%  135.39us         2  67.695us  64.959us  70.432us  force_corr_gpu_124_gpu
                    0.05%  123.78us        20  6.1880us  5.8880us  6.7520us  void gemv2T_kernel_val&lt;int, int, double2, double2, double2, double2, int=128, int=16, int=4, int=4, bool=1, bool=0, cublasGemvParams&lt;cublasGemvTensorStridedBatched&lt;double2 const &gt;, cublasGemvTensorStridedBatched&lt;double2 const &gt;, cublasGemvTensorStridedBatched&lt;double2&gt;, double2&gt;&gt;(double2 const , double2, double2)
                    0.05%  120.93us        20  6.0460us  5.9520us  6.3680us  gen_us_dj_gpu_197_gpu
                    0.04%  103.62us        10  10.361us  10.304us  10.848us  stres_us_gpu_91_gpu
                    0.04%  96.448us         7  13.778us  13.568us  14.176us  dfunct_gpum_newd_gpu_311_gpu
                    0.04%  94.400us         1  94.400us  94.400us  94.400us  stres_ewa_gpu_155_gpu
                    0.03%  72.992us        10  7.2990us  7.1360us  8.4160us  init_wfc_gpu_391_gpu
                    0.03%  72.800us         2  36.400us  34.432us  38.368us  force_lc_gpu_119_gpu
                    0.03%  72.768us         1  72.768us  72.768us  72.768us  stres_har_gpu_77_gpu
                    0.03%  69.888us        10  6.9880us  6.8480us  7.4240us  atomic_wfc_gpu_85_gpu
                    0.03%  67.520us         1  67.520us  67.520us  67.520us  stres_loc_gpu_155_gpu
                    0.02%  59.712us        10  5.9710us  5.8880us  6.2080us  rotate_wfc_k_gpu_132_gpu
                    0.01%  24.384us         6  4.0640us  3.7760us  4.9600us  void reduce_1Block_kernel&lt;double2, int=64, int=6, cublasGemvTensorStridedBatched&lt;double2&gt;, cublasGemvTensorStridedBatched&lt;double2 const &gt;, cublasGemvTensorStridedBatched&lt;double2&gt;&gt;(double2 const *, double2, double2, int, double2 const *, double2, cublasGemvTensorStridedBatched&lt;double2&gt;, double2 const , cublasPointerMode_t, cublasLtEpilogue_t, cublasGemvTensorStridedBatched&lt;biasType&lt;double2 const value_type, double2&gt;::type const &gt;)
                    0.01%  24.224us         6  4.0370us  3.7760us  4.8960us  void dot_kernel&lt;double2, int=64, int=1, cublasDotParams&lt;cublasGemvTensorStridedBatched&lt;double2 const &gt;, cublasGemvTensorStridedBatched&lt;double2&gt;&gt;&gt;(double2 const )
                    0.01%  21.568us         1  21.568us  21.568us  21.568us  stres_loc_gpu_98_gpu
                    0.01%  15.264us         6  2.5440us  2.4640us  2.8160us  __pgi_dev_cumemset_4n
                    0.00%  9.7280us         1  9.7280us  9.7280us  9.7280us  dvloc_of_g_gpu_184_gpu
      API calls:   56.54%  877.99ms      1715  511.95us     489ns  409.99ms  cudaFree
                   19.84%  308.14ms       900  342.37us  1.4400us  295.87ms  cudaDeviceSynchronize
                    7.03%  109.13ms     20152  5.4150us  4.5100us  310.44us  cudaLaunchKernel
                    4.31%  66.931ms      1542  43.405us  4.6000us  3.8148ms  cudaMemcpy
                    2.19%  34.061ms      2479  13.739us  3.8100us  180.48us  cudaMemcpyAsync
                    2.12%  32.959ms      2557  12.889us  4.6510us  239.27us  cudaEventSynchronize
                    1.43%  22.244ms        20  1.1122ms  822.92us  2.3907ms  cuDeviceTotalMem
                    1.11%  17.296ms      6645  2.6020us     749ns  186.38us  cudaEventRecord
                    0.93%  14.380ms      1744  8.2450us  1.8290us  1.3001ms  cudaMalloc
                    0.75%  11.621ms      1977  5.8780us     149ns  1.6835ms  cuDeviceGetAttribute
                    0.57%  8.8800ms     20143     440ns     330ns  287.69us  cudaDeviceGetAttribute
                    0.49%  7.6111ms      1656  4.5960us  4.0700us  31.689us  cuLaunchKernel
                    0.33%  5.1501ms     10579     486ns     330ns  239.62us  cudaGetDevice
                    0.29%  4.4656ms         6  744.27us  448.31us  2.1013ms  cudaGetDeviceProperties
                    0.28%  4.4199ms     10835     407ns     150ns  2.2176ms  cudaGetLastError
                    0.25%  3.8660ms      1384  2.7930us  1.8200us  8.4200us  cudaStreamSynchronize
                    0.20%  3.1513ms       689  4.5730us  3.3890us  20.390us  cudaMemsetAsync
                    0.19%  3.0171ms      2557  1.1790us  1.0100us  11.680us  cudaEventElapsedTime
                    0.15%  2.3771ms       256  9.2850us  1.9900us  152.75us  cudaSetDevice
                    0.15%  2.2786ms      1524  1.4950us     780ns  12.790us  cudaEventQuery
                    0.14%  2.1870ms       145  15.083us  7.2200us  21.080us  cudaMemcpy2D
                    0.11%  1.7847ms       147  12.140us  4.5000us  738.97us  cudaMallocHost
                    0.11%  1.7611ms      2336     753ns     469ns  12.960us  cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags
                    0.09%  1.3806ms        20  69.028us  41.230us  387.93us  cuDeviceGetName
                    0.09%  1.3584ms       133  10.213us  4.9500us  107.07us  cudaMemcpyToSymbol
                    0.09%  1.3446ms       508  2.6460us  2.2900us  14.350us  cudaFuncGetAttributes
                    0.05%  771.33us       146  5.2830us  3.7500us  20.409us  cudaFreeHost
                    0.04%  625.29us        44  14.211us  1.3800us  205.11us  cudaStreamCreate
                    0.02%  380.08us       552     688ns     510ns  3.6400us  cudaStreamIsCapturing
                    0.02%  359.66us        44  8.1740us  3.8090us  92.571us  cudaStreamDestroy
                    0.01%  195.34us       267     731ns     620ns  15.100us  cudaEventCreate
                    0.01%  170.44us       562     303ns     200ns  1.2400us  cuCtxPushCurrent
                    0.01%  158.23us       562     281ns     200ns     810ns  cuCtxPopCurrent
                    0.01%  116.94us       146     800ns     480ns  2.9910us  cudaPointerGetAttributes
                    0.00%  54.041us        90     600ns     460ns  2.8110us  cudaEventCreateWithFlags
                    0.00%  40.090us         3  13.363us  2.4000us  32.530us  cudaStreamCreateWithFlags
                    0.00%  20.707us        24     862ns     250ns  6.3000us  cuDeviceGet
                    0.00%  18.040us         4  4.5100us  1.8300us  9.0200us  cuDeviceGetPCIBusId
                    0.00%  17.489us         4  4.3720us  2.5690us  9.3200us  cuInit
                    0.00%  16.104us        45     357ns     180ns  1.9900us  cudaGetFuncBySymbol
                    0.00%  13.147us         8  1.6430us  1.3110us  3.2490us  cudaEventDestroy
                    0.00%  5.2070us        20     260ns     150ns     580ns  cuDeviceGetUuid
                    0.00%  3.3580us         7     479ns     230ns     940ns  cuDeviceGetCount
                    0.00%  2.6790us        10     267ns     180ns     360ns  cuCtxGetCurrent
                    0.00%  1.2700us         2     635ns     190ns  1.0800us  cudaGetDeviceCount
                    0.00%  1.1300us         4     282ns     240ns     380ns  cuDriverGetVersion
                    0.00%     920ns         5     184ns     170ns     200ns  cuCtxGetDevice
                    0.00%     309ns         1     309ns     309ns     309ns  cudaDriverGetVersion
                    0.00%     200ns         1     200ns     200ns     200ns  cudaRuntimeGetVersion
</code></pre>
<p><img src="Apps/SC/SC21/func-util.png" alt="" />
<img src="Apps/SC/SC21/gpu-utilization.png" alt="" />
<img src="Apps/SC/SC21/kernel-profile.png" alt="" />
<img src="Apps/SC/SC21/memory.png" alt="" />
<img src="Apps/SC/SC21/stall-reason.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ramble"><a class="header" href="#ramble">ramBLe</a></h1>
<h2 id="install-1"><a class="header" href="#install-1">Install</a></h2>
<h3 id="lib"><a class="header" href="#lib">Lib</a></h3>
<p><a href="Apps/SC/SC21/../../../Libs/Boost.html">Boost</a></p>
<p>just add the code into <code>SConstruct</code> to tell <code>scons</code> where is the boost lib is.</p>
<pre><code class="language-python">libPaths.append(&quot;/opt/spack/opt/spack/linux-debian10-zen2/gcc-10.2.0/boost-1.70.0-m4ttgcfqixwe22z5kz7bpp7mbqdspdbg/lib&quot;)
cppPaths.append(&quot;/opt/spack/opt/spack/linux-debian10-zen2/gcc-10.2.0/boost-1.70.0-m4ttgcfqixwe22z5kz7bpp7mbqdspdbg/include&quot;)
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><h1 id="benchmark"><a class="header" href="#benchmark">Benchmark</a></h1>
<p>è¿™é‡Œæ”¾ç½®HPCç«èµ›ä¸­ Benchmark æœ‰å…³èµ„æ–™ï¼Œæ–‡æ¡£éƒ¨åˆ†ç”¨äºå¯¹æ–°ç”Ÿçš„åŸ¹è®­ã€‚</p>
<div style="break-before: page; page-break-before: always;"></div><!-- TITLE: Hpcg Dat -->
<!-- SUBTITLE: A quick summary of Hpcg Dat -->
<h1 id="dat-specs"><a class="header" href="#dat-specs">.dat Specs</a></h1>
<h2 id="asc20"><a class="header" href="#asc20">ASC20</a></h2>
<pre><code>HPCG benchmark input file
Sandia National Laboratories; University of Tennessee, Knoxville
384 256 256
60
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><!-- TITLE: HPL hpl.dat Config -->
<!-- SUBTITLE: Ancestral hpl.dat config file -->
<h1 id="hpl-dat-config-file"><a class="header" href="#hpl-dat-config-file">HPL .dat config file</a></h1>
<h2 id="asc18"><a class="header" href="#asc18">ASC18</a></h2>
<p>The following is the HPL <code>.dat</code> configuration file template from ASC18.</p>
<pre><code>HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
1            # of problems sizes (N)
67200 65280 62976 65280 96000 65280 38400 96000 102400 168960 153600 76800   142848 153600 142848 124416 96256 142848 124416 115200 110592 96256 Ns
1             # of NBs
384 768 384 768 1024 768 896 768 1024 512 384 640 768 896 960 1024 1152 1280 384 640 960 768 640 256  960 512 768 1152         NBs
0            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
2 1 2 1        Ps
1 2 2 4        Qs
16.0         threshold
1            # of panel fact
0 1 2        PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
2 8          NBMINs (&gt;= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
0 1 2        RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
2 0 2          BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM)
1            # of lookahead depth
0            DEPTHs (&gt;=0)
1            SWAP (0=bin-exch,1=long,2=mix)
192          swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
0            U  in (0=transposed,1=no-transposed) form
1            Equilibration (0=no,1=yes)
8            memory alignment in double (&gt; 0)
</code></pre>
<h2 id="asc20-1"><a class="header" href="#asc20-1">ASC20</a></h2>
<p>The following is the HPL <code>.dat</code> configuration file template from ASC20.
Machine Spec : 8 Tesla V100</p>
<pre><code>HPLinpack benchmark input file
Innovative Computing Laboratory, University of Tennessee
HPL.out      output file name (if any)
6            device out (6=stdout,7=stderr,file)
2            # of problems sizes (N)
175104 178176 165888 168960 172032 175104 Ns
2             # of NBs
384 256 128 256 384 192 288 320 384 384 768 1024 768 896 768 1024 512 384 640 768 896 960 1024 1152 1280 384 640 960 768 640 256  960 512 768 1152         NBs
0            PMAP process mapping (0=Row-,1=Column-major)
1            # of process grids (P x Q)
4 2 8 1 2 1        Ps
4 8 2 2 4        Qs
16.0         threshold
1            # of panel fact
0 1 2        PFACTs (0=left, 1=Crout, 2=Right)
1            # of recursive stopping criterium
2 8          NBMINs (&gt;= 1)
1            # of panels in recursion
2            NDIVs
1            # of recursive panel fact.
0 1 2        RFACTs (0=left, 1=Crout, 2=Right)
1            # of broadcast
2 0 2          BCASTs (0=1rg,1=1rM,2=2rg,3=2rM,4=Lng,5=LnM)
1            # of lookahead depth
0            DEPTHs (&gt;=0)
1            SWAP (0=bin-exch,1=long,2=mix)
192          swapping threshold
1            L1 in (0=transposed,1=no-transposed) form
0            U  in (0=transposed,1=no-transposed) form
1            Equilibration (0=no,1=yes)
8            memory alignment in double (&gt; 0)
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><h1 id="devops"><a class="header" href="#devops">DevOps</a></h1>
<p>è¿™é‡Œæ”¾ç½®æœ‰å…³HPCç¯å¢ƒç»´æŠ¤æœ‰å…³çš„èµ„æ–™ã€‚</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="grafana"><a class="header" href="#grafana">Grafana</a></h1>
<p>æ•°æ®æºï¼š<a href="https://zhuanlan.zhihu.com/p/53376293">telegraf</a></p>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><h1 id="salt-stack"><a class="header" href="#salt-stack">Salt Stack</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pbs-1"><a class="header" href="#pbs-1">PBS</a></h1>
<h1 id="slurm"><a class="header" href="#slurm">Slurm</a></h1>
<p>æœ¬è¶…ç®—ä½¿ç”¨çš„æ˜¯ Slurmï¼Œè¯¦ç»†çš„é…ç½®å¯è§ <a href="https://www.victoryang00.cn/wordpress/2021/01/31/pei-he-mou-xi-jing-shi-yong-de-slurm-cai-keng-ri-j/">é…åˆæŸæˆç²¾ä½¿ç”¨çš„ slurm è¸©å‘æ—¥è®°</a>ã€‚</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="singularity"><a class="header" href="#singularity">Singularity</a></h1>
<p>ä¼¯å…‹åˆ©å‡ºå“çš„ä¸€ä¸ªç”¨æˆ·æ€æ”¾ docker çš„åœ°æ–¹ã€‚</p>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><h1 id="chisel"><a class="header" href="#chisel">Chisel</a></h1>
<p>æœ‰å…³æˆ‘ä»¬æ˜¯å¦æœ‰å¿…è¦å­¦ä¹ ä¸€é—¨é€»è¾‘ç”µè·¯æè¿°è¯­è¨€å»å®ç°ä¸€ä¸ª CPU æˆ–è€…ä¸€ä¸ªè·¯ç”±å™¨ï¼Ÿ æˆ‘è®¤ä¸ºæ˜¯ååˆ†å¿…è¦çš„ï¼Œè¿™è®©å¤§å®¶å¯ä»¥ä»åº•å¾€ä¸Šçœ‹ä½ çš„ Data å’Œ Instruction çš„å˜åŠ¨ã€‚</p>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><h1 id="go"><a class="header" href="#go">Go</a></h1>
<p>æ­¤è¯­è¨€æ˜¯ä¸ªéå¸¸ç®€å•ä¸Šæ‰‹çš„è¯­è¨€ï¼ŒåŒæ—¶ç”±äºå¤§å‚ä½¿ç”¨è¿‡å¤šï¼Œå¸‚é¢ä¸Šå¼€æºçš„å·¥å…·éƒ½éå¸¸å¯ç”¨ã€‚ç¬”è€…åœ¨å®ä¹ çš„æ—¶å€™å­¦ä¹ çš„ï¼Œ<code>module</code> ç­‰åŒ…ç®¡ç†å·¥å…·åœ¨å¹¶è¡Œæ–‡ä»¶ç³»ç»Ÿä¸Šé¢çš„ <code>channel</code> + <code>context</code> é‡æ–°å®ç°éå¸¸å¿«ï¼Œé‚£ä¸ªä»£ç ä¹Ÿå°±æ•°åè¡Œå¤„ç†ä¸€äº›å¹¶è¡Œè´¨è¯¢çš„çŠ¶æ€æœºå³å¯ï¼Œä¹Ÿç”¨å…¶å†™è¿‡ä¸€äº› eBPF çš„ä»£ç ç”¨äºæ›´å¥½çš„è·å¾—æ–‡ä»¶ IO çš„å®æ—¶æ€§èƒ½ã€‚</p>
<h2 id="ä¸€äº›å°å·¥å…·"><a class="header" href="#ä¸€äº›å°å·¥å…·">ä¸€äº›å°å·¥å…·</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rust"><a class="header" href="#rust">Rust</a></h1>
<p>Rust æ˜¯å¥½æ´»ï¼Œè‡ªä»æˆ‘æ ¡2016å¹´ä»¥ Rust è¯­è¨€å¼€è®¾ CS100ï¼ˆç¨‹åºè¯­è¨€è®¾è®¡ï¼‰å¼€å§‹ï¼Œä¸Šç§‘å¤§å°±æˆä¸ºäº†å®£ä¼ Rustçš„å ¡å’ï¼Œä¸­å›½ Rust ä¹‹çˆ¶å¼ æ±‰ä¸œå…ˆç”ŸåŠå®£å‘ Rust çš„å„ç•Œäººå£«é€‰æ‹©æ¨å¹¿ Rust çš„æœ€ä½³åœ°ç‚¹å°±ä¼šé€‰æ‹©ä¸Šç§‘å¤§ï¼Œè¿™é›¨ä¸ riscv ç±»ä¼¼ã€‚å†™å°çš„bashå·¥å…·ï¼ˆ Zero Cost Abstraction çš„ cffi ï¼‰ã€å†™å¤§å‹ï¼ˆ10w+ lineï¼‰çš„ç³»ç»Ÿæ–¹å‘ç¨‹åºå¿…å¤‡ã€‚ç”±äºè¯­è¨€ç‰¹æ€§æœ‰å¾ˆå¤šçš„é™æ€æ£€æŸ¥ï¼Œä¼šæŒ‡å¯¼å¤§å®¶å¯¹äºå†…å­˜ç®¡ç†ï¼Œå¼‚æ­¥ç¼–ç¨‹æœ‰æ›´æ·±åˆ»çš„ç†è§£ã€‚</p>
<h2 id="å­¦ä¹ å‚è€ƒèµ„æ–™"><a class="header" href="#å­¦ä¹ å‚è€ƒèµ„æ–™">å­¦ä¹ å‚è€ƒèµ„æ–™</a></h2>
<ol>
<li>rCore - æ¸…åç»´æŠ¤çš„æ•™å­¦æ“ä½œç³»ç»Ÿ</li>
<li>Libra - è„¸ä¹¦ç»´æŠ¤çš„åŒºå—é“¾æ•°æ®åº“</li>
<li>é£ä¹¦ - Tokio ä»£ç æ± </li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="libs"><a class="header" href="#libs">Libs</a></h1>
<p>è¿™é‡Œæ”¾ç½®ä¸€äº›å¸¸ç”¨åº“çš„å®‰è£…å’Œä½¿ç”¨äº‹é¡¹ã€‚</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="boost"><a class="header" href="#boost">Boost</a></h1>
<p><a href="https://www.boost.org/">website</a></p>
<h2 id="spack"><a class="header" href="#spack">Spack</a></h2>
<pre><code class="language-bash">spack info boost
spack install boost
</code></pre>
<h2 id="source"><a class="header" href="#source">Source</a></h2>
<pre><code class="language-bash">./bootstrap.sh --help
# Select your configuration options and invoke ./bootstrap.sh again without the --help option. Unless you have write permission in your system's /usr/local/ directory, you'll probably want to at least use

./bootstrap.sh --prefix=path/to/installation/prefix
# to install somewhere else. Also, consider using the --show-libraries and --with-libraries=library-name-list options to limit the long wait you'll experience if you build everything. Finally,

./b2 install
# will leave Boost binaries in the lib/ subdirectory of your installation prefix. You will also find a copy of the Boost headers in the include/ subdirectory of the installation prefix, so you can henceforth use that directory as an #include path in place of the Boost root directory.

# and add to PATH and LD and INCLUDE
</code></pre>
<h2 id="ç‰ˆæœ¬ç›¸å…³é—®é¢˜"><a class="header" href="#ç‰ˆæœ¬ç›¸å…³é—®é¢˜">ç‰ˆæœ¬ç›¸å…³é—®é¢˜</a></h2>
<p>This is Version 3 of the Filesystem library. Version 2 is not longer supported. 1.49.0 was the last release of Boost to supply Version 2ã€‚</p>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><h1 id="armforge"><a class="header" href="#armforge">ArmForge</a></h1>
<p><a href="https://www.arm.com">Arm</a> Forge æ˜¯ä¸€ä¸ª Arm å…¬å¸å‡ºå“çš„å¯¹é«˜æ€§èƒ½ç¨‹åºçš„è½¯ä»¶ã€‚æœ€å¼ºå¤§çš„åœ°æ–¹å°±æ˜¯ä»–å¯¹ CPU GPU éƒ½éå¸¸é€‚ç”¨ï¼ŒåŒ…æ‹¬ Arm DDT å’Œ Arm MAP çš„å·¥å…·ã€‚Arm DDT æ˜¯ä¸šç•Œé¢†å…ˆçš„å¹¶è¡Œè°ƒè¯•å™¨ï¼Œæ”¯æŒ MPIã€CUDA å’Œ OpenMPã€‚Arm MAPæ˜¯ç”¨äºMPIã€OpenMPå’Œ Vectorized ç¨‹åºçš„ä½å¼€é”€çº¿çº§å‰–æå™¨ã€‚</p>
<ul>
<li><a href="https://www.Arm.com/products/">ä¸‹è½½ Arm Forgeï¼ˆDDT + MAPï¼‰</a>ï¼Œå·²ä½¿ç”¨ spack éƒ¨ç½²</li>
<li><a href="https://developer.arm.com/docs/101136/latest/arm-forge/introduction">Arm Forgeç”¨æˆ·æŒ‡å—</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="uprof"><a class="header" href="#uprof">uProf</a></h1>
<p>AMD å‡ºå“çš„ä¸€æ¬¾ perf å·¥å…·ï¼Œå¢åŠ äº†ä¸€äº› X86 è¶…é›†çš„ metricsï¼Œä½† UI æ¯”è¾ƒä¸‘ã€‚</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vtune"><a class="header" href="#vtune">Vtune</a></h1>
<p>éƒ½è¯´åšä½“ç³»ç»“æ„çš„äººæœ€æ‡‚åš Profilingï¼Œä¸€ä¸ªå¥½çš„ Profiling å·¥å…·ä¸€å®šæ˜¯æœ‰å¥½çš„å¯¹ CPU å®æ—¶æ€§èƒ½çš„æŠ½è±¡ï¼Œæœ€ç®€å•çš„å‘½ä»¤æ˜¯ <code>rdstc</code>ï¼Œ armä¸Šä¹Ÿæœ‰ç±»ä¼¼çš„å®ç°</p>
<h2 id="abi-æ”¯æŒ"><a class="header" href="#abi-æ”¯æŒ">ABI æ”¯æŒ</a></h2>
<p>profiler éœ€è¦æœ‰å¯¹ Intel Proceccor å„ç§ metrics çš„å‡½æ•°å®ç°ï¼Œåœ¨å®‰è£…Vtuneçš„è¿‡ç¨‹ä¸­ä¼šç¼–è¯‘å¯¹å½“å‰ç³»ç»Ÿçš„ <a href="https://software.intel.com/content/www/us/en/develop/articles/intel-performance-counter-monitor.html">PMU</a> çš„åŠ¨æ€é“¾æ¥åº“ï¼Œæ„ä¸ºå¯¹ Intel <a href="https://software.intel.com/content/www/us/en/develop/articles/intel-performance-counter-monitor.html">PMU</a> çš„ ABIæ”¯æŒï¼Œæˆ‘é˜Ÿä½¿ç”¨çš„ epyc æœ‰epycé€‚ç”¨çš„é­”æ”¹ç‰ˆ <a href="https://github.com/AMDESE/amd-perf-tools">PMU Tools</a>ã€‚ç°åœ¨ä½“ç³»ç»“æ„å®‰å…¨ç•Œå­¦æœ¯ä¸»æµå¯¹ PMU çš„ç ”ç©¶å¾ˆæ·±ï¼Œå› ä¸ºå…¶æ³„éœ²äº†éƒ¨åˆ†å¯¹ CPU å®æ—¶çš„çŠ¶æ€ï¼Œå¯ä»¥ä»ä¸­è·å–æƒ³è¦çš„ä¸œè¥¿ã€‚</p>
<p>X86 éœ€è¦æ”¯æŒçš„ perf å‚æ•°æ¯”è¾ƒæœ‰é™ï¼Œlinuxä»kprobeï¼Œuprobeè¿™äº›å®˜æ–¹æ”¯æŒçš„ microprocessor samplingæœ‰å¾ˆæœ‰ç”¨çš„ï¼Œè¿™äº›å·²è¢«eBPFæ‰€é‡‡ç”¨ã€‚</p>
<p>Intel Compiler åœ¨ç¼–è¯‘ broadwell ä»¥ä¸Šæ¶æ„ä¼˜åŒ–æ—¶ä¸»è¦åšäº†ä¸‰ä»¶å¯¹æ€§èƒ½å½±å“å¾ˆå¤§çš„äº‹æƒ…ï¼š</p>
<ol>
<li>æ¿€è¿›çš„è·¨ basic block ä¼˜åŒ– + Vectorization + Loop Unroll</li>
<li>Load å’Œ Store åœ¨æ»¡è¶³ TSO æ¡ä»¶ä¸‹çš„æ¿€è¿›çš„é‡æ’ï¼ŒåŒæ—¶æ¿€è¿›çš„æ•´åˆæ•°æ®ï¼Œæ”¯æŒ store buffer bypassï¼Œmovntã€‚åŒæ—¶ä¹Ÿæ˜¯ icc åç«¯ Bug çš„ä¸»è¦æ¥æºã€‚ä¹Ÿæ˜¯å¤§å‚ä¸å¤ªç”¨ä»–çš„åŸå› ã€‚é™¤ HPC å¤–ï¼Œå¤§å®¶ä¸€èˆ¬ç…§ gcc æ ‡å‡†ã€‚</li>
<li>è‡ªå·±ç»´æŠ¤çš„ TBB çº¿ç¨‹æ± ï¼ˆéå¸¸å¿«ï¼‰ï¼Œè‡ªå·±ç»´æŠ¤çš„ malloc_alignï¼Œè‡ªå·±ç»´æŠ¤çš„ç›¸å…³åº“ã€‚</li>
</ol>
<p>æœ‰å…³å¦‚ä½•æ›´å¥½çš„é€‚é… Intel çš„CPUï¼Œå¯ä»¥å‚è€ƒ Lammps çš„ <a href="https://t.co/6DUtP6Falq?amp=1">Intel Package</a>ã€‚å…¶ä½¿ç”¨è®¿é—®è€…æ¨¡å¼å¯¹ Intel processorçš„å¯„å­˜å™¨èµ„æºã€‚</p>
<p>æœ‰å…³å¯¹ç”¨æˆ·æ€æ–‡ä»¶ç³»ç»Ÿçš„é€‚é…ï¼ŒVtune æä¾›äº†å¯¹ PM å¸¦å®½çš„å®æ—¶æµ‹è¯•ï¼Œè¿™ä¸ª metrics è²Œä¼¼å¾ˆéš¾æ‹¿åˆ°ã€‚</p>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><!-- TITLE: Cluster Setup -->
<!-- SUBTITLE: Cluster setup procedure -->
<h1 id="cluster-setup-æµç¨‹"><a class="header" href="#cluster-setup-æµç¨‹">Cluster Setup æµç¨‹</a></h1>
<p>å®Œæ•´æµç¨‹ &amp; è¸©å‘ç¬”å½•</p>
<h2 id="æœºå™¨ä¿¡æ¯--ç¡¬ä»¶å‡†å¤‡"><a class="header" href="#æœºå™¨ä¿¡æ¯--ç¡¬ä»¶å‡†å¤‡">æœºå™¨ä¿¡æ¯ &amp; ç¡¬ä»¶å‡†å¤‡</a></h2>
<ul>
<li>èŠ‚ç‚¹ï¼š4 èŠ‚ç‚¹ ï¼ˆnode1~4ï¼Œnode1 ä¸º <em>ä¸»èŠ‚ç‚¹</em>ï¼‰</li>
<li>ç½‘ç»œï¼šEthernetï¼ˆ<code>192.168.&lt;A&gt;.x</code>ï¼‰ä¸ IBï¼ˆ<code>192.168.&lt;B&gt;.x</code>ï¼‰
<ul>
<li>æ˜ŸçŠ¶æ‹“æ‰‘</li>
<li>Setup æ—¶ä¸»èŠ‚ç‚¹éœ€è¿æ¥å¤–ç½‘</li>
</ul>
</li>
<li>ç¡¬ç›˜ï¼šæ¯ä¸ªèŠ‚ç‚¹ä¸€å—ç³»ç»Ÿç›˜ï¼Œä¸»èŠ‚ç‚¹é¢å¤–æŒ‚ä¸€å— SSD ä½œä¸ºå…±äº«å­˜å‚¨</li>
<li>Clonezilla é•œåƒ U ç›˜ * 1ï¼ˆé•œåƒç›´æ¥è§£å‹å³å¯ï¼Œæ•…ä¸‹è¿°å®‰è£…æ—¶éœ€è¦ BIOS è®¾ç½®ä¸º UEFI æ¨¡å¼ï¼‰</li>
<li>Clean Minimal CentOS7 é•œåƒ U ç›˜ * 1ï¼ˆåŒä¸Šï¼‰</li>
</ul>
<h2 id="centos-æ“ä½œç³»ç»Ÿå®‰è£…"><a class="header" href="#centos-æ“ä½œç³»ç»Ÿå®‰è£…">CentOS æ“ä½œç³»ç»Ÿå®‰è£…</a></h2>
<p>ä¸‹è½½ <strong>CentOS-7 Minimal é•œåƒ</strong> äº U ç›˜ï¼Œæ’äºä¸»èŠ‚ç‚¹</p>
<blockquote>
<p>å¦‚æœä¸»æ¿ BIOS å¯åŠ¨æ¨¡å¼ä¸æ˜¯ UEFI åˆ™å‹¿å¿˜åœ¨å¯åŠ¨æ—¶ä¿®æ”¹ ;(
ä¸»èŠ‚ç‚¹éœ€è¦ä½¿ç”¨å¤–ç½® Clonezilla é•œåƒ U ç›˜ï¼Œæ•…ä¹ŸæŠŠ U ç›˜å¯åŠ¨é¡ºåºç½®å‰</p>
</blockquote>
<p>ä¸»èŠ‚ç‚¹å¼€æœº â€œinstall CentOS 7â€</p>
<blockquote>
<p>å¦‚æœ Install åè§¦å‘äº† <code>dracut-init... timeout</code>ï¼Œåœ¨ä¹‹åä¼šè·³å…¥ <code>dracut</code> å‘½ä»¤è¡Œï¼Œè¾“å…¥ <code>lsblk</code> åæ‰¾åˆ° U ç›˜è®¾å¤‡ï¼Œè®°ä¸‹ <code>LABEL=AAA</code> çš„å€¼ï¼Œè€Œå <code>reboot</code>ï¼›ç„¶ååœ¨é€‰æ‹©ç•Œé¢æŒ‰ <code>e</code>ï¼Œä¿®æ”¹ç¬¬äºŒè¡Œä¸­çš„ <code>LABEL=BBB</code> çš„ç¬¬ä¸€æ®µ ä¸º <code>AAA</code>ï¼Œç„¶å <code>ctrl+x</code> å³å¯
å¦ä¸€ç§æ–¹æ³•æ˜¯å°†LABEL=CentOS\x207\x20x\86_64ä¿®æ”¹ä¸ºLABEL=CentOS\x207\x20x\8
https://blog.csdn.net/qq_36937234/article/details/82996998
https://access.redhat.com/solutions/2515741</p>
</blockquote>
<p>éœ€è°ƒæ•´é¡¹å¦‚ä¸‹ï¼š</p>
<ul>
<li>ç£ç›˜åˆ†åŒº <code>/</code> + <code>/boot</code> å³å¯ï¼Œæ ¹ç›®å½•å„å­ç›®å½•ä¸åˆ†æ•£åˆ†åŒºï¼Œæ ¼ä¸ºext4</li>
<li>ä¸»æœºå Hostname è®¾ä¸º <code>node1</code></li>
</ul>
<p>å¾…å®‰è£…å®Œæˆï¼Œä»¥ <code>root</code> ç”¨æˆ·å¯æ­£å¸¸ç™»é™†</p>
<p><strong>å…³é—­ SELinux</strong>ï¼šä¿®æ”¹ <code>/etc/selinux/config</code>ï¼Œè®¾ç½® <code>SELINUX=disabled</code></p>
<p><strong>å…³é—­ Firewall é˜²ç«å¢™</strong>ï¼š</p>
<pre><code class="language-bash">systemctl stop firewalld.service
systemctl disable firewalld.service
</code></pre>
<blockquote>
<p>å¾ˆå¤šé—®é¢˜éƒ½ä¼šç”±ä¸Šè¿°ä¸¤ä¸ªå®‰å…¨æœåŠ¡å¼•èµ·ï¼Œåœ¨è¶…ç®—æ¯”èµ›å†…ç½‘ç¯å¢ƒä¸‹æ— ç”¨ï¼Œå…ˆå…¨å…³é—­</p>
</blockquote>
<h2 id="ä»¥å¤ªç½‘è¿æ¥é…ç½®"><a class="header" href="#ä»¥å¤ªç½‘è¿æ¥é…ç½®">ä»¥å¤ªç½‘è¿æ¥é…ç½®</a></h2>
<p>å…ˆé…ç½®ä¸»èŠ‚ç‚¹è¿æ¥å¤–ç½‘ï¼Œå†å°†å„èŠ‚ç‚¹å†…ç½‘è¿æ¥</p>
<h3 id="ethernet-å¤–ç½‘"><a class="header" href="#ethernet-å¤–ç½‘">Ethernet å¤–ç½‘</a></h3>
<p>è¿æ¥å¤–ç½‘ä»¥å¤ªç½‘çº¿ï¼ˆè®°ä½å¯¹åº”ç½‘å£ <code>&lt;INTERFACE&gt;</code>ï¼Œe.g. <code>eno2</code>ï¼‰</p>
<p>ä½¿ç”¨ <code>ip</code> æŒ‡ä»¤æ£€æŸ¥ DNS åœ°å€ç­‰ä¿¡æ¯ï¼Œè€Œååœ¨è¾“å…¥ <code>nmtui</code> è¿›å…¥ GUI ç½‘ç»œè®¾ç½®ç•Œé¢ï¼Œè®¾ç½®å¤–ç½‘è¿æ¥ä¸º DHCP æ¨¡å¼ï¼Œå¡«å…¥ 
DNS æœåŠ¡å™¨åœ°å€ï¼Œè€Œåä½¿ç”¨ <code>curl</code> è¿›è¡Œæ ¡ç½‘ç™»å½•ï¼š</p>
<pre><code class="language-bash">$ dhclient -v &lt;INTERFACE&gt;
$ curl -X POST --data â€œuserName=&lt;USERNAME&gt;&amp;password=&lt;PASSWD&gt;&amp;hasValidateCode=false&amp;authLan=zh_CNâ€ https://10.15.44.172:8445/PortalServer//Webauth/webAuthAction\!login.action
</code></pre>
<p>æ­¤æ—¶å¯ä»¥è¿æ¥å¤–ç½‘ï¼Œéœ€è¦è®°å½•ä¸‹æœ¬æœº ip åœ°å€ä»¥ä¾¿è¿œç¨‹è¿æ¥ï¼ˆæ ¡ç½‘ä¸­é€”ä¸å…³æœºåˆ™ DHCP ip åœ°å€åº”è¯¥ä¸ä¼šæ”¹å˜ï¼‰ï¼›<code>curl &lt;URL&gt;</code> æ£€æŸ¥å¤–ç½‘è¿æ¥</p>
<h3 id="ethernet-å†…ç½‘"><a class="header" href="#ethernet-å†…ç½‘">Ethernet å†…ç½‘</a></h3>
<p>åŒæ ·ä½¿ç”¨ <code>ip</code> å·¥å…·çœ‹åˆ°ç½‘å…³åœ°å€ç­‰ä¿¡æ¯ï¼Œä½¿ç”¨ <code>nmtui</code> GUI å·¥å…·å¯¹å†…ç½‘ç½‘å£ï¼ˆe.g. <code>eno1</code>ï¼‰è¿›è¡Œé…ç½®ï¼Œe.g. ä¸»èŠ‚ç‚¹ <code>192.168.&lt;A&gt;.1</code></p>
<h2 id="é©±åŠ¨ä¸‹è½½--å®‰è£…"><a class="header" href="#é©±åŠ¨ä¸‹è½½--å®‰è£…">é©±åŠ¨ä¸‹è½½ &amp; å®‰è£…</a></h2>
<p>IB é©±åŠ¨ &amp; Nvidia é©±åŠ¨ï¼Œå®‰è£…åœ¨é»˜è®¤ä½ç½®ï¼ˆå› ä¸ºå…±äº«ç›˜è¿˜æœªé…ç½®ï¼‰ï¼Œæ•…åœ¨æ‹·ç›˜å‰åšå¥½</p>
<h3 id="ib-é©±åŠ¨å’Œé…ç½®"><a class="header" href="#ib-é©±åŠ¨å’Œé…ç½®">IB é©±åŠ¨å’Œé…ç½®</a></h3>
<p><a href="https://blog.csdn.net/oPrinceme/article/details/51001849">IB é©±åŠ¨</a></p>
<h3 id="nvidia-é©±åŠ¨"><a class="header" href="#nvidia-é©±åŠ¨">Nvidia é©±åŠ¨</a></h3>
<p><code>yum install kernel-dev epel-release dkms</code> æ¥æ·»åŠ  <code>Redhat</code> æº åŠ å…¶ä»– Nvidia é©±åŠ¨ä¾èµ–</p>
<p>å…³é—­é»˜è®¤ <code>nouveau</code> æ˜¾å¡é©±åŠ¨ï¼š</p>
<pre><code class="language-bash">$ vi /etc/default/grub    # `GRUB_CMDLINE_LINUX` é€‰é¡¹ä¸­æ·»åŠ  `nouveau.modeset=0`
$ grub2-mkconfig -o /boot/efi/EFI/centos/grub.cfg
$ reboot
</code></pre>
<blockquote>
<p>ä¸è¦ç”¨å®˜ç½‘çš„ rpm åŒ…å®‰è£…é©±åŠ¨ ;(</p>
</blockquote>
<p>é‡å¯åï¼Œåœ¨å®˜ç½‘æŸ¥è¯¢æ‰€ç”¨å¡å¯¹åº”çš„æœ€æ–°é©±åŠ¨ç‰ˆæœ¬ <code>&lt;VER.SUB&gt;</code>ï¼ˆe.g. V100 ç›®å‰æœ€æ–°ä¸º <code>410.79</code>ï¼‰ï¼Œè·å–å®‰è£…è„šæœ¬å¹¶å®‰è£…ï¼š</p>
<pre><code class="language-bash">$ wget http://us.download.nvidia.com/XFree86/Linux-x86_64/&lt;VER.SUB&gt;/NVIDIA-Linux-x86_64-&lt;VER.SUB&gt;.run
$ bash NVIDIA-Linux-x86_64-&lt;VER.SUB&gt;.run --kernel-source-path /usr/src/kernels/xxx    # è‹¥æŠ¥é”™åŠ æ­¤é€‰é¡¹å®‰è£…è¯•è¯•
</code></pre>
<p>è¯• <code>nvidia-smi</code> æŒ‡ä»¤çœ‹èƒ½å¦è·å–åˆ°æ˜¾å¡ä¿¡æ¯</p>
<h2 id="å…‹éš†åˆ›å»ºå­èŠ‚ç‚¹"><a class="header" href="#å…‹éš†åˆ›å»ºå­èŠ‚ç‚¹">å…‹éš†åˆ›å»ºå­èŠ‚ç‚¹</a></h2>
<p>å…ˆå®‰è£…å¿…è¦çš„åŸºæœ¬å·¥å…·ä»¥å‡å°‘é‡å¤å·¥ä½œï¼š<code>yum -y install &lt;TOOL-NAME&gt;</code>ï¼š</p>
<ul>
<li>NFSï¼š<code>nfs-utils rpcbind</code></li>
<li>Lmodï¼š<code>environment-modules</code></li>
<li>å…¶ä»–ï¼š<code>gcc gcc-c++ perl wget</code>ï¼ˆé€šè¿‡ <code>yum</code> é¢„å®‰è£… gcc ç”¨äºå¹¶è¡Œåº“å·¥å…·ç­‰çš„ç¼–è¯‘å®‰è£…ï¼‰</li>
</ul>
<p>ä¸»èŠ‚ç‚¹å…³æœºï¼Œæ’å…¥ <em>Clonezilla</em> å·¥å…·ç›˜ï¼Œä»å®ƒå¯åŠ¨ï¼Œå°†ä¸»èŠ‚ç‚¹ç³»ç»Ÿç›˜å…‹éš†è‡³å­èŠ‚ç‚¹ç³»ç»Ÿç›˜å†…ï¼ˆå‹¿æé”™æ‹·è´ Source &amp; Target ç›˜æ–¹å‘ï¼‰ï¼š<a href="https://www.tecmint.com/linux-centos-ubuntu-disk-cloning-backup-using-clonezilla">https://www.tecmint.com/linux-centos-ubuntu-disk-cloning-backup-using-clonezilla</a></p>
<p>å­èŠ‚ç‚¹æ’å…¥ç³»ç»Ÿç›˜åï¼Œåˆ†åˆ«ç™»é™†å„å­èŠ‚ç‚¹ï¼Œä¿®æ”¹ä¸»æœºåå’Œé™æ€ ip åœ°å€ï¼ˆå†…ç½‘ç½‘å£ï¼‰ï¼Œä»¥ä¾¿äº’è”è¯†åˆ«èº«ä»½ï¼Œæ³¨æ„ <strong>4 èŠ‚ç‚¹ ip å’Œ ä¸»æœºå äº’ä¸ç›¸åŒ</strong>ï¼š</p>
<pre><code class="language-bash"># e.g. node2 èŠ‚ç‚¹
$ hostnamectl set-hostname node2
$ vi /etc/sysconfig/network-scripts/ifcfg-&lt;INTERFACE&gt;   #ä¿®æ”¹ IPADDR=192.168.&lt;A&gt;.2
</code></pre>
<h2 id="æ•°æ®ç›˜-nfs-å…±äº«over-ib-rdma"><a class="header" href="#æ•°æ®ç›˜-nfs-å…±äº«over-ib-rdma">æ•°æ®ç›˜ NFS å…±äº«ï¼ˆover IB RDMAï¼‰</a></h2>
<p><a href="https://developer.nvidia.com/blog/doubling-network-file-system-performance-with-rdma-enabled-networking/">howto-configure-nfs-over-rdma--roce-x</a></p>
<p>Maybe useful according to teacher Zhang</p>
<pre><code>opensmd
openibd
</code></pre>
<h2 id="æ•°æ®ç›˜-nfs-å…±äº«over-tcpå¤‡é€‰"><a class="header" href="#æ•°æ®ç›˜-nfs-å…±äº«over-tcpå¤‡é€‰">æ•°æ®ç›˜ NFS å…±äº«ï¼ˆover TCPï¼‰å¤‡é€‰</a></h2>
<p>ä¸»èŠ‚ç‚¹æ’ä¸Šç”¨ä½œå…±äº«ç›˜çš„ç¡¬ç›˜ï¼Œ<code>lsblk</code> æŸ¥çœ‹æ–°ç¡¬ç›˜å·²æ’ä¸ŠåŠåç§°ï¼Œå¯çœ‹åˆ°å‡ºç° e.g. <code>sdb1</code> ç›˜ï¼ˆæ ¹æ®å¤§å°åˆ¤æ–­é‚£ä¸ªä¸ºå…±äº«ç›˜ï¼Œå‹¿æé”™ï¼‰</p>
<blockquote>
<p>æ ¼å¼åŒ–ç£ç›˜æµç¨‹å¤‡å¿˜ï¼š</p>
<p><code>$ fdisk /dev/sdb1</code>
<code>$     n                     # æ–°å»ºåˆ†åŒº</code>
<code>$     p 1 [Enter] [Enter]   # æ•´ä¸ªç›˜å»ºç«‹ä¸ºä¸€ä¸ªå¤§ä¸»åˆ†åŒº</code></p>
</blockquote>
<p>æŒ‚è½½è¯¥ç£ç›˜å¹¶åœ¨å…¶ä¸­å»ºç«‹æ¬²å…±äº«çš„ç›®å½•ï¼ˆ<code>/home</code> å’Œ <code>/opt</code>ï¼‰:</p>
<pre><code class="language-bash">$ mount /dev/nvme0n1 /mnt/nfs
$ mkdir /mnt/nfs/home
$ mkdir /mnt/nfs/opt
</code></pre>
<p>ä¸»èŠ‚ç‚¹å¯åŠ¨ NFS serverï¼Œç¼–è¾‘å…±äº«ç›®å½•é…ç½® <code>/etc/exports</code>ï¼Œæ·»åŠ æ¡ç›®ï¼ˆ<em>æ³¨æ„ä¸å¤šåŠ ç©ºæ ¼</em>ï¼‰ï¼š</p>
<pre><code>/mnt/nfs/home 192.168.&lt;A&gt;.0/24(rw,no_root_squash,no_all_squash,sync)
/mnt/nfs/opt  192.168.&lt;A&gt;.0/24(rw,no_root_squash,no_all_squash,sync)
</code></pre>
<p>å‚æ•°è§£é‡Šï¼š</p>
<ul>
<li><code>rw</code>ï¼šå¯è¯»å†™</li>
<li><code>no_*_squash</code>ï¼šå®¢æˆ·èŠ‚ç‚¹ä»¥ * èº«ä»½ä½¿ç”¨æ—¶ä¸é™çº§ä¸ºåŒ¿åæ™®é€šç”¨æˆ·</li>
<li><code>sync</code>ï¼šå„ç«¯çš„å†™æ“ä½œåŒæ­¥è‡³ç£ç›˜</li>
</ul>
<p>å¼€å¯æœåŠ¡å¹¶è®¾ç½®å¼€æœºè‡ªå¯ï¼š</p>
<pre><code class="language-bash">$ exportfs -r
$ service rpcbind start
$ service nfs start
$ chkconfig rpcbind on
$ chkconfig nfs on
</code></pre>
<p>è®¾ç½®ä¸»èŠ‚ç‚¹é˜²ç«å¢™å…è®¸ NFS è®¿é—®è¯·æ±‚ï¼š</p>
<pre><code class="language-bash">$ firewall-cmd --permanent --add-service=mountd
$ firewall-cmd --permanent --add-service=nfs
$ firewall-cmd --permanent --add-service=rpc-bind
$ firewall-cmd --reload
</code></pre>
<p>ä¿®æ”¹ <code>/etc/fstab</code>ï¼Œä½¿ä¸»èŠ‚ç‚¹å°†å…±äº«ç›®å½• <em>bind mount</em> ï¼ˆç›®å½•æ ‘åˆ°ç›®å½•æ ‘æŒ‚è½½ï¼‰ åˆ° <code>/home</code> <code>/opt</code>ï¼Œå­èŠ‚ç‚¹ç”± NFS å°†ä¸»èŠ‚ç‚¹ç›®å½•æŒ‚è½½ï¼š</p>
<pre><code># On node1ï¼Œåœ¨ /etc/fstab æ–‡ä»¶æœ«å°¾æ·»åŠ 
/dev/nvme0n1    /mnt/nfs    ext4    rw,user,exec,suid,dev,auto,async
/mnt/nfs/home   /home       none    rw,user,exec,suid,dev,auto,async,bind
/mnt/nfs/opt    /opt        none    rw,user,exec,suid,dev,auto,async,bind

# On node2~4ï¼Œåœ¨ /etc/fstab æ–‡ä»¶æœ«å°¾æ·»åŠ 
node1:/mnt/nfs/home    /home   nfs     rw,user,exec,suid,dev,auto,async
node1:/mnt/nfs/home    /opt    nfs     rw,user,exec,suid,dev,auto,async
</code></pre>
<p>è€Œåæ¯æ¬¡å¼€æœºåï¼Œå„èŠ‚ç‚¹å‡ç™»å…¥ root ç”¨æˆ·ï¼Œ<strong>å…ˆåœ¨ä¸»èŠ‚ç‚¹</strong> <code>mount -a</code>ï¼Œ<strong>ååœ¨å„å­èŠ‚ç‚¹</strong> <code>mount -a</code> å³å¯æˆåŠŸæŒ‚è½½å…±äº«ç›®å½•</p>
<blockquote>
<p>å…¨æ‰‹åŠ¨æŒ‚è½½æ–¹å¼å¤‡å¿˜ï¼Œå¼€æœºåé¦–å…ˆåœ¨ä¸»èŠ‚ç‚¹ï¼š</p>
<p><code>$ mount /dev/nvme0n1 /mnt/nfs</code>
<code>$ mount --bind /mnt/nfs/home /home</code>
<code>$ mount --bind /mnt/nfs/opt /opt</code></p>
<p>è€Œååœ¨å„å­èŠ‚ç‚¹ï¼š</p>
<p><code>$ showmount -e node1     # æ£€æµ‹æ˜¯å¦æœ‰æ¥è‡ªä¸»èŠ‚ç‚¹çš„ nfs å…±äº«</code>
<code>$ mount -t nfs node1:/mnt/nfs/home /home</code>
<code>$ mount -t nfs node1:/mnt/nfs/opt  /opt</code></p>
</blockquote>
<blockquote>
<p>å‡ºç° â€œStale file handleâ€ é—®é¢˜ / â€œAccess deniedâ€ é—®é¢˜ï¼Œåœ¨ä¸»èŠ‚ç‚¹é‡å¯ NFSï¼š<code>systemctl restart nfs</code> åå†æŒ‚è½½ä¸€éå³å¯</p>
</blockquote>
<h2 id="ssh-å…å¯†ç ç™»å½•é…ç½®"><a class="header" href="#ssh-å…å¯†ç ç™»å½•é…ç½®">SSH å…å¯†ç ç™»å½•é…ç½®</a></h2>
<p>é¦–å…ˆé…ç½® root ç”¨æˆ·ç›¸äº’ <em>ssh</em> å…å¯†ç™»é™†ï¼Œ<strong>æ‰€æœ‰èŠ‚ç‚¹å¯¹ä¹‹é—´å‡éœ€é…ç½®</strong>ï¼Œe.g. åœ¨ä¸»èŠ‚ç‚¹ <code>/root</code> ä¸‹ï¼š</p>
<pre><code class="language-bash">$ ssh-keygen            # ä½ç½®åç§°é»˜è®¤
$ ssh-copy-id node1    # è‡ªèº«èŠ‚ç‚¹ä¹Ÿéœ€æ‹·è´
$ ...
$ ssh-copy-id node4
</code></pre>
<p>è€Œååœ¨å„è‡ªèŠ‚ç‚¹ <em>å‡</em> åˆ›å»ºæ™®é€šç”¨æˆ·ï¼Œæ³¨æ„ <strong>ç›¸åŒåç§°</strong> &amp; <strong>ç›¸åŒ uid</strong> &amp; <strong>ç›¸åŒ group (gid)</strong> &amp; <strong>ç›¸åŒå¯†ç </strong>ï¼š</p>
<pre><code class="language-bash">$ useradd &lt;USERNAME&gt; -m
$ passwd &lt;USERNAME&gt;
$     [Type new PASSWORD] [Type again]    # è®¾ç½®å¯†ç ï¼Œä¸è¦é€šè¿‡ useradd çš„ -p é€‰é¡¹ï¼Œå¯†ç ä¸è§„èŒƒæ—¶ä¼šå¤±è´¥
</code></pre>
<blockquote>
<p>å¯†ç é€šè¿‡ <code>passwd</code> æŒ‡ä»¤è®¾ç½®ï¼Œå¦åˆ™å¯†ç ä¸è§„èŒƒæ—¶ <code>-p</code> é€‰é¡¹å¯èƒ½å¤±è´¥ä¸”ä¸ä¼šç»™å‡ºæç¤º
æŒ‰ç›¸åŒé¡ºåºåˆ›å»ºå³æ˜¯ï¼Œå¯ä»¥é€šè¿‡ <code>cat /etc/passwd</code> æ£€æŸ¥</p>
</blockquote>
<p>ä»»æ„èŠ‚ç‚¹è¿›å…¥æ™®é€šç”¨æˆ·ï¼Œç”Ÿæˆå¹¶æ‹·è´å¯†é’¥ï¼ˆæ³¨æ„æ™®é€šç”¨æˆ· Home ç›®å½•å…±äº«ï¼‰ï¼š</p>
<pre><code class="language-bash">$ su testuser
$ cd
$ ssh-keygen
      [Enter] [Enter] [Enter]
$ ssh-copy-id localhost
</code></pre>
<h2 id="ç¼–è¯‘å™¨å¹¶è¡Œåº“å’Œç¯å¢ƒçš„å®‰è£…"><a class="header" href="#ç¼–è¯‘å™¨å¹¶è¡Œåº“å’Œç¯å¢ƒçš„å®‰è£…">ç¼–è¯‘å™¨ã€å¹¶è¡Œåº“å’Œç¯å¢ƒçš„å®‰è£…</a></h2>
<p>ç¯å¢ƒå®‰è£…ç›®å½•æ–‡ä»¶æ ‘æ”¾ç½®äº <code>/opt</code> ä¸‹</p>
<blockquote>
<p>æ‰€éœ€ç¯å¢ƒåŠå®‰è£…æµç¨‹ - è§ â€œ<a href="Sysadmin/environment-installation.html">Environment Installation</a>â€</p>
</blockquote>
<h2 id="ç¯å¢ƒ-environment-modules-é…ç½®"><a class="header" href="#ç¯å¢ƒ-environment-modules-é…ç½®">ç¯å¢ƒ Environment Modules é…ç½®</a></h2>
<p>å‰é¢å·²ä¸‹è½½è¿‡ Lmod å·¥å…·ï¼›å…±äº«ç›˜ä¸­ <code>mkdir /opt/modulefiles</code> ä½œä¸º modulefile å­˜å‚¨ä½ç½®ï¼Œè€Œååœ¨ <strong>æ¯ä¸ª</strong> èŠ‚ç‚¹å›ºå®š modulefile æœç´¢è·¯å¾„ï¼Œäº <code>/etc/environment</code> ä¸­æ·»åŠ è¡Œï¼š</p>
<pre><code class="language-bash">export MODULEPATH=/opt/modulefiles
</code></pre>
<blockquote>
<p>å‹¿å¿˜ <code>source /etc/environment</code></p>
</blockquote>
<blockquote>
<p>æ›¾ç”¨ modulefile æ–‡ä»¶ - è§ â€œ<a href="Sysadmin/environment-modules.html">Modulefile Records</a>â€</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><!-- TITLE: Environment Installation -->
<!-- SUBTITLE: Installation records for environment dependencies -->
<h1 id="ç¯å¢ƒå®‰è£…è®°å½•"><a class="header" href="#ç¯å¢ƒå®‰è£…è®°å½•">ç¯å¢ƒå®‰è£…è®°å½•</a></h1>
<p>ç¯å¢ƒå®‰è£…æ–¹å¼ + ç›®å½•æ ‘ä½ç½®</p>
<h2 id="å®‰è£…ç›®å½•æ ‘ç»“æ„"><a class="header" href="#å®‰è£…ç›®å½•æ ‘ç»“æ„">å®‰è£…ç›®å½•æ ‘ç»“æ„</a></h2>
<pre><code>|- /opt/
    |- openmpi/
        |- 4.0
        |- 3.1
        |- ...
    |- mpich/
    |- intel/    # Intel å…¨å®¶ç¦
    |- blas/
    |- gcc/
    |- cuda/     # Nvidia CUDA
    |- pgi/      # CUDA PGi Edition
    |- netcdf/
        |- netcdf-c/
        |- netcdf-fort/
    |- pnetcdf
</code></pre>
<blockquote>
<p>ç¼–è¯‘å®‰è£…åŸºæœ¬å…­è¿ï¼š</p>
<p><code>$ wget [SOURCE_URL]</code>
<code>$ tar zxvf openmpi-4.0.0.tar.gz</code>
<code>$ cd openmpi-4.0.0/</code>
<code>$ ./configure --prefix=â€˜/opt/mpi/openmpi/4.0â€™   # æ³¨æ„è§„åˆ’å¥½ä½ç½®</code>
<code>$ make -j8</code>
<code>$ make install</code></p>
</blockquote>
<h2 id="åŒ…ç®¡ç†ç³»ç»Ÿ"><a class="header" href="#åŒ…ç®¡ç†ç³»ç»Ÿ">åŒ…ç®¡ç†ç³»ç»Ÿ</a></h2>
<blockquote>
<p><a href="https://spack.io/">spack</a>
Environment Modules
äºŒé€‰ä¸€ï¼Œ <code>spack</code> åŸºæœ¬ä¸Šå°±æ˜¯å¯¹ç³»ç»Ÿçº§çš„<code>modules</code>çš„é«˜å±‚APIï¼Œä»ASC20å¼€å§‹ï¼Œæˆ‘ä»¬å¼€å§‹ä½¿ç”¨<code>spack</code>ã€‚ä¸ºä¿è¯ç›®å½•æ ‘nfså…±äº«ç»“æ„ï¼ŒæŠŠ<code>spack</code> æ”¾åœ¨/opt ç›®å½•ä¸‹ã€‚</p>
</blockquote>
<blockquote>
<p>$ git clone https://github.com/spack/spack.git
$ cd spack/bin
$ ./spack install libelf # test
$ echo &quot;export PATH=$PATH:/opt/spack/bin&quot; &gt;&gt; ~/.bashrc
$ echo &quot;. /opt/spack/share/spack/setup-env.sh&quot; &gt;&gt; ~/.bashrc
$ bash</p>
</blockquote>
<p>ä¾èµ–ä»¥åŠç‰ˆæœ¬spec</p>
<blockquote>
<p>$ spack install intel^gcc@9</p>
</blockquote>
<p>åœ¨æµ‹è¯•æ—¶ä½¿ç”¨</p>
<blockquote>
<p>$ spack load intel^gcc@9
ä¹Ÿå¯ä»¥<code>module avail</code> åæŸ¥çœ‹éœ€è¦load çš„ç¯å¢ƒ<code>module load intel</code></p>
</blockquote>
<p>æ·»åŠ æ–°çš„ç¼–è¯‘å™¨ï¼Œåœ¨è‡ªå·±ç¼–è¯‘å®‰è£…å¥½ä¸€ä¸ªç¼–è¯‘å™¨å¹¶åœ¨<code>PATH</code>ä¸­å¯ä»¥æ‰¾åˆ°çš„æ—¶å€™ï¼Œå¯ä»¥ä½¿ç”¨<code>spack find</code>å‘½ä»¤ï¼Œä¹‹åå°±å¯ä»¥ç”¨è¿™ä¸ªç¼–è¯‘å™¨<code>@intel</code>æ¥ç¼–è¯‘æ–°çš„ç¼–è¯‘å™¨äº†ã€‚</p>
<p>ç‰¹æ®Šæ³¨æ„ï¼Œåœ¨ç¼–è¯‘å®‰è£…<code>mpi</code>,<code>omp</code>è¿‡ç¨‹ä¸­ä¸€å®šè¦å¼€å¯ --with-rdma é€‰é¡¹ä»¥æ”¯æŒInfiniband.</p>
<h2 id="ç¼–è¯‘å™¨"><a class="header" href="#ç¼–è¯‘å™¨">ç¼–è¯‘å™¨</a></h2>
<ol>
<li><strong>gcc</strong> (åŒ…å« <strong>gfortran</strong>) - Version 7.4 + 5.5 + 4.9.4 + 4.4.7
<ul>
<li><code>CentOS</code> è‡ªå¸¦çš„gccç‰ˆæœ¬è¿‡è€ï¼Œå¯ä»¥ä½¿ç”¨ <code>scl enable devtoolset-9 bash</code>ä»¥æ”¯æŒæœ€æ–°gccç‰¹æ€§ã€‚</li>
<li>7.4ï¼š<a href="http://ftp.gnu.org/gnu/gcc/gcc-7.4.0/gcc-7.4.0.tar.gz">gcc-7.4.0.tar.gz</a></li>
<li>5.5ï¼š<a href="http://ftp.gnu.org/gnu/gcc/gcc-5.5.0/gcc-5.5.0.tar.gz">gcc-5.5.0.tar.gz</a></li>
<li>4.4.7ï¼š<a href="http://ftp.gnu.org/gnu/gcc/gcc-4.4.7/gcc-4.4.7.tar.gz">gcc-4.4.7.tar.gz</a></li>
</ul>
</li>
<li><strong>icc</strong> &amp; <strong>ifort</strong>ï¼šåŒ…å«äº <em>Intel Parallel Studio XE</em> ä¸­</li>
</ol>
<h2 id="intel-parallel-studio-xe-å…¨å®¶æ¡¶"><a class="header" href="#intel-parallel-studio-xe-å…¨å®¶æ¡¶">Intel Parallel Studio XE å…¨å®¶æ¡¶</a></h2>
<p><strong>Parallel Studio XE</strong>ï¼šæŒ‰ç…§ <a href="https://www.slothparadise.com/how-to-setup-the-intel-compilers-on-a-cluster">This Procedure</a> è·å–å’Œå®‰è£…ï¼Œ19-20 æˆæƒå¦‚ä¸‹</p>
<ul>
<li>åºåˆ—å· S4ZD-MMZJXJ96 (è‹¥å¤±æ•ˆï¼Œå¯ä»¥å‰å¾€è‹±ç‰¹å°”å®˜ç½‘ç”³è¯·ï¼Œåœ¨ä¸‹æ–¹register centerï¼Œè‹¥ä¸ºspack å®‰è£…åªéœ€åœ¨å®‰è£…è¿‡ç¨‹ä¸­è¾“å…¥å³å¯)</li>
<li>URLï¼š<a href="http://registrationcenter-download.intel.com/akdlm/irc_nas/tec/15088/parallel_studio_xe_2019_update2_cluster_edition.tgz">parallel_studio_xe_2019_update2_cluster_edition.tgz</a></li>
<li>LICENSEï¼šå®˜ç½‘ Registration Center ä¸‹è½½åä¼ è‡³ Server</li>
</ul>
<blockquote>
<p><code>icc</code> <code>ifort</code> <code>mkl</code> <code>IntelMPI</code> å‡åŒ…å«äº Parallel Studio XE ä¸­
<code>spack install intel</code></p>
</blockquote>
<p>ç”±äºcudaåªæ”¯æŒç¼–è¯‘å®ƒçš„ç¼–è¯‘å™¨å¤´æ–‡ä»¶åœ¨gcc-7æ ‡å‡†ä»¥å‰ï¼Œæ‰€ä»¥å»ºè®®ä½¿ç”¨intel@18.0.3</p>
<h2 id="mpi"><a class="header" href="#mpi">MPI</a></h2>
<ol>
<li><strong>OpenMPI</strong> - Version 4.0 + 3.1 + 3.0 + 2.1
<ul>
<li>4.0ï¼š<a href="https://download.open-mpi.org/release/open-mpi/v4.0/openmpi-4.0.0.tar.gz">openmpi-4.0.0.tar.gz</a></li>
<li>3.1ï¼š<a href="https://download.open-mpi.org/release/open-mpi/v3.1/openmpi-3.1.3.tar.gz">openmpi-3.1.3.tar.gz</a></li>
<li>3.0ï¼š<a href="https://download.open-mpi.org/release/open-mpi/v3.0/openmpi-3.0.3.tar.gz">openmpi-3.0.3.tar.gz</a></li>
<li>2.1ï¼š<a href="https://download.open-mpi.org/release/open-mpi/v2.1/openmpi-2.1.6.tar.gz">openmpi-2.1.6.tar.gz</a></li>
</ul>
</li>
<li><strong>MPICH</strong> - Version 3.3 + 3.2.1
<ul>
<li>3.3ï¼š<a href="http://www.mpich.org/static/downloads/3.3/mpich-3.3.tar.gz">mpich-3.3.tar.gz</a></li>
<li>3.2.1ï¼š<a href="http://www.mpich.org/static/downloads/3.2.1/mpich-3.2.1.tar.gz">mpich-3.2.1.tar.gz</a></li>
</ul>
</li>
<li><strong>IntelMPI</strong>ï¼šåŒ…å«äº <em>Intel Parallel Studio XE</em> ä¸­</li>
</ol>
<h2 id="nvidia-cuda"><a class="header" href="#nvidia-cuda">Nvidia CUDA</a></h2>
<ul>
<li><strong>CUDA Toolkit</strong>ï¼š<code>spack install cuda@10.2</code> ä»¥æ”¯æŒä¸åŒç‰ˆæœ¬ã€‚</li>
<li><strong>PGi Edition</strong>ï¼š<code>spack install pgi@19.10</code></li>
</ul>
<h2 id="math-libraries"><a class="header" href="#math-libraries">Math Libraries</a></h2>
<ol>
<li><strong>MKL</strong>ï¼šåŒ…å«äº <em>Intel Parallel Studio XE</em> ä¸­</li>
<li><strong>OpenBLAS</strong>ï¼š<code>spack install openblas</code></li>
</ol>
<h2 id="netcdf-io"><a class="header" href="#netcdf-io">NetCDF I/O</a></h2>
<p>ç”¨äºASC19 çš„IO500é¢˜ç›®ä¸­ã€‚</p>
<div style="break-before: page; page-break-before: always;"></div><!-- TITLE: Environment Modules -->
<!-- SUBTITLE: Environment Module Management & Backups -->
<h1 id="modulefile--spack-è®°å½•"><a class="header" href="#modulefile--spack-è®°å½•">Modulefile &amp; Spack è®°å½•</a></h1>
<p>Environment Module: Modulefiles ç›®å½•æ ‘ç»“æ„ + å¤‡ä»½</p>
<h2 id="modulefiles-ç›®å½•æ ‘ç»“æ„-deprecated"><a class="header" href="#modulefiles-ç›®å½•æ ‘ç»“æ„-deprecated">Modulefiles ç›®å½•æ ‘ç»“æ„ ï¼ˆDeprecatedï¼‰</a></h2>
<pre><code class="language-bash">|- /opt/modulefiles    # è·¯å¾„å¹¶éå®Œå…¨æŒ‰ç…§å†²çªå…³ç³»ç»„ç»‡ï¼Œmodulefile ä¸­å†²çªå…³ç³»è¦æ³¨æ„
    |- mpi/
        |- openmpi/
            |- 4.0
            |- 3.1
            |- ...
        |- mpich/
        |- intelmpi/
    |- math/
        |- mkl/
        |- blas/
    |- compilers/
        |- gcc/
        |- icc/
        |- ifort/
    |- cuda/
        |- nvidia/
        |- pgi/
    |- netcdf/
        |- pnetcdf/
        |- netcdf-c/
        |- netcdf-fort/
</code></pre>
<h2 id="spack-ç®€å•æ•™ç¨‹"><a class="header" href="#spack-ç®€å•æ•™ç¨‹">Spack ç®€å•æ•™ç¨‹</a></h2>
<pre><code class="language-c">â¯ spack info gcc
AutotoolsPackage:   gcc

Description:
    The GNU Compiler Collection includes front ends for C, C++, Objective-C,
    Fortran, Ada, and Go, as well as libraries for these languages.

Homepage: https://gcc.gnu.org

Maintainers: @michaelkuhn @alalazo

Externally Detectable:
    True (version, variants)

Tags:
    None

Preferred version:
    11.2.0    https://ftpmirror.gnu.org/gcc/gcc-11.2.0/gcc-11.2.0.tar.xz

Safe versions:
    master    [git] git://gcc.gnu.org/git/gcc.git on branch master
    11.2.0    https://ftpmirror.gnu.org/gcc/gcc-11.2.0/gcc-11.2.0.tar.xz
    11.1.0    https://ftpmirror.gnu.org/gcc/gcc-11.1.0/gcc-11.1.0.tar.xz
    10.3.0    https://ftpmirror.gnu.org/gcc/gcc-10.3.0/gcc-10.3.0.tar.xz
    10.2.0    https://ftpmirror.gnu.org/gcc/gcc-10.2.0/gcc-10.2.0.tar.xz
    10.1.0    https://ftpmirror.gnu.org/gcc/gcc-10.1.0/gcc-10.1.0.tar.xz
    9.4.0     https://ftpmirror.gnu.org/gcc/gcc-9.4.0/gcc-9.4.0.tar.xz
    9.3.0     https://ftpmirror.gnu.org/gcc/gcc-9.3.0/gcc-9.3.0.tar.xz
    9.2.0     https://ftpmirror.gnu.org/gcc/gcc-9.2.0/gcc-9.2.0.tar.xz
    9.1.0     https://ftpmirror.gnu.org/gcc/gcc-9.1.0/gcc-9.1.0.tar.xz
    8.5.0     https://ftpmirror.gnu.org/gcc/gcc-8.5.0/gcc-8.5.0.tar.xz
    8.4.0     https://ftpmirror.gnu.org/gcc/gcc-8.4.0/gcc-8.4.0.tar.xz
    8.3.0     https://ftpmirror.gnu.org/gcc/gcc-8.3.0/gcc-8.3.0.tar.xz
    8.2.0     https://ftpmirror.gnu.org/gcc/gcc-8.2.0/gcc-8.2.0.tar.xz
    8.1.0     https://ftpmirror.gnu.org/gcc/gcc-8.1.0/gcc-8.1.0.tar.xz
    7.5.0     https://ftpmirror.gnu.org/gcc/gcc-7.5.0/gcc-7.5.0.tar.xz
    7.4.0     https://ftpmirror.gnu.org/gcc/gcc-7.4.0/gcc-7.4.0.tar.xz
    7.3.0     https://ftpmirror.gnu.org/gcc/gcc-7.3.0/gcc-7.3.0.tar.xz
    7.2.0     https://ftpmirror.gnu.org/gcc/gcc-7.2.0/gcc-7.2.0.tar.xz
    7.1.0     https://ftpmirror.gnu.org/gcc/gcc-7.1.0/gcc-7.1.0.tar.bz2
    6.5.0     https://ftpmirror.gnu.org/gcc/gcc-6.5.0/gcc-6.5.0.tar.bz2
    6.4.0     https://ftpmirror.gnu.org/gcc/gcc-6.4.0/gcc-6.4.0.tar.bz2
    6.3.0     https://ftpmirror.gnu.org/gcc/gcc-6.3.0/gcc-6.3.0.tar.bz2
    6.2.0     https://ftpmirror.gnu.org/gcc/gcc-6.2.0/gcc-6.2.0.tar.bz2
    6.1.0     https://ftpmirror.gnu.org/gcc/gcc-6.1.0/gcc-6.1.0.tar.bz2
    5.5.0     https://ftpmirror.gnu.org/gcc/gcc-5.5.0/gcc-5.5.0.tar.bz2
    5.4.0     https://ftpmirror.gnu.org/gcc/gcc-5.4.0/gcc-5.4.0.tar.bz2
    5.3.0     https://ftpmirror.gnu.org/gcc/gcc-5.3.0/gcc-5.3.0.tar.bz2
    5.2.0     https://ftpmirror.gnu.org/gcc/gcc-5.2.0/gcc-5.2.0.tar.bz2
    5.1.0     https://ftpmirror.gnu.org/gcc/gcc-5.1.0/gcc-5.1.0.tar.bz2
    4.9.4     https://ftpmirror.gnu.org/gcc/gcc-4.9.4/gcc-4.9.4.tar.bz2
    4.9.3     https://ftpmirror.gnu.org/gcc/gcc-4.9.3/gcc-4.9.3.tar.bz2
    4.9.2     https://ftpmirror.gnu.org/gcc/gcc-4.9.2/gcc-4.9.2.tar.bz2
    4.9.1     https://ftpmirror.gnu.org/gcc/gcc-4.9.1/gcc-4.9.1.tar.bz2
    4.8.5     https://ftpmirror.gnu.org/gcc/gcc-4.8.5/gcc-4.8.5.tar.bz2
    4.8.4     https://ftpmirror.gnu.org/gcc/gcc-4.8.4/gcc-4.8.4.tar.bz2
    4.7.4     https://ftpmirror.gnu.org/gcc/gcc-4.7.4/gcc-4.7.4.tar.bz2
    4.6.4     https://ftpmirror.gnu.org/gcc/gcc-4.6.4/gcc-4.6.4.tar.bz2
    4.5.4     https://ftpmirror.gnu.org/gcc/gcc-4.5.4/gcc-4.5.4.tar.bz2

Variants:
    Name [Default]               Allowed values          Description
    =========================    ====================    ===================================================

    binutils [off]               on, off                 Build via binutils
    bootstrap [on]               on, off                 Enable 3-stage bootstrap
    graphite [off]               on, off                 Enable Graphite loop optimizations (requires ISL)
    languages [c,c++,fortran]    ada, brig, c, c++,      Compilers and runtime libraries to build
                                 fortran, go, java,
                                 jit, lto, objc,
                                 obj-c++
    nvptx [off]                  on, off                 Target nvptx offloading to NVIDIA GPUs
    piclibs [off]                on, off                 Build PIC versions of libgfortran.a and libstdc++.a
    strip [off]                  on, off                 Strip executables to reduce installation size

Installation Phases:
    autoreconf    configure    build    install

Build Dependencies:
    binutils  cuda  diffutils  flex  gmp  gnat  iconv  isl  mpc  mpfr  zip  zlib  zstd

Link Dependencies:
    binutils  cuda  gmp  gnat  iconv  isl  mpc  mpfr  zlib  zstd

Run Dependencies:
    binutils

Virtual Packages:
    gcc@7: languages=go provides golang@:1.8
    gcc@6: languages=go provides golang@:1.6.1
    gcc@5: languages=go provides golang@:1.4
    gcc@4.9: languages=go provides golang@:1.2
    gcc@4.8.2: languages=go provides golang@:1.1.2
    gcc@4.8: languages=go provides golang@:1.1
    gcc@4.7.1: languages=go provides golang@:1
    gcc@4.6: languages=go provides golang
</code></pre>
<p>å¾—åˆ°ç›¸å…³ä¾èµ–ï¼Œå¯ä»¥æŸ¥çœ‹ä½ ç°åœ¨å¦‚æœå®‰è£… spack æä¾›çš„ä¾èµ–</p>
<pre><code class="language-c">â¯ spack spec gcc  
Input spec
--------------------------------
gcc

Concretized
--------------------------------
gcc@11.2.0%apple-clang@12.0.5~binutils+bootstrap~graphite~nvptx~piclibs~strip languages=c,c++,fortran patches=ecc5ac43951b34cbc5db15f585b4e704c42e2e487f9ed4c24fadef3f3857930b arch=darwin-bigsur-skylake
    ^diffutils@2.8.1%apple-clang@12.0.5 arch=darwin-bigsur-skylake
    ^gmp@6.2.1%apple-clang@12.0.5 arch=darwin-bigsur-skylake
        ^autoconf@2.71%apple-clang@12.0.5 arch=darwin-bigsur-skylake
        ^automake@1.16.4%apple-clang@12.0.5 arch=darwin-bigsur-skylake
        ^libtool@2.4.6%apple-clang@12.0.5 arch=darwin-bigsur-skylake
        ^m4@1.4.6%apple-clang@12.0.5+sigsegv patches=c0a408fbffb7255fcc75e26bd8edab116fc81d216bfd18b473668b7739a4158e arch=darwin-bigsur-skylake
    ^libiconv@1.16%apple-clang@12.0.5 arch=darwin-bigsur-skylake
    ^mpc@1.1.0%apple-clang@12.0.5 arch=darwin-bigsur-skylake
        ^mpfr@4.1.0%apple-clang@12.0.5 arch=darwin-bigsur-skylake
            ^autoconf-archive@2019.01.06%apple-clang@12.0.5 arch=darwin-bigsur-skylake
            ^texinfo@4.8%apple-clang@12.0.5 arch=darwin-bigsur-skylake
    ^zlib@1.2.11%apple-clang@12.0.5+optimize+pic+shared arch=darwin-bigsur-skylake
    ^zstd@1.5.0%apple-clang@12.0.5~ipo~legacy~lz4~lzma~multithread+programs+shared+static~zlib build_type=RelWithDebInfo arch=darwin-bigsur-skylake
        ^cmake@3.21.1%apple-clang@12.0.5~doc+ncurses+openssl+ownlibs~qt build_type=Release arch=darwin-bigsur-skylake
</code></pre>
<p>å¦‚æœæƒ³ä½¿ç”¨ç‰¹å®šä¾èµ–æˆ–è€…ä¾èµ–ç³»ç»Ÿçš„åŒ…ï¼Œä¼šåœ¨ <code>~/.spack/package</code> ä¸‹å¾—åˆ°ï¼Œå…¶ä½¿ç”¨æ–¹æ³•å¯è§ <a href="https://developer.amd.com/spack/build-customization/">AMD</a></p>
<pre><code class="language-c">â¯ spack external find

â¯ cat ~/.spack/package.json
       â”‚ File: /Users/victoryang/.spack/packages.yaml
â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   1   â”‚ packages:
   2   â”‚   autoconf:
   3   â”‚     externals:
   4   â”‚     - spec: autoconf@2.71
   5   â”‚       prefix: /usr/local
   6   â”‚   automake:
   7   â”‚     externals:
   8   â”‚     - spec: automake@1.16.4
   9   â”‚       prefix: /usr/local
  10   â”‚   bash:
  11   â”‚     externals:
  12   â”‚     - spec: bash@3.2.57
  13   â”‚       prefix: /
  14   â”‚   bazel:
  15   â”‚     externals:
  16   â”‚     - spec: bazel@4.1.0
  17   â”‚       prefix: /usr/local
  18   â”‚   bison:
  19   â”‚     externals:
  20   â”‚     - spec: bison@2.3
  21   â”‚       prefix: /usr
  22   â”‚   bzip2:
  23   â”‚     externals:
  24   â”‚     - spec: bzip2@1.0.6
  25   â”‚       prefix: /usr
  26   â”‚   cmake:
  27   â”‚     externals:
  28   â”‚     - spec: cmake@3.21.1
  29   â”‚       prefix: /usr/local
  30   â”‚   diffutils:
  31   â”‚     externals:
  32   â”‚     - spec: diffutils@2.8.1
  33   â”‚       prefix: /usr
...
</code></pre>
<p>å®‰è£…åçš„å‚æ•°å¤§è‡´éœ€è¦çš„æœ‰å‡ ä¸ªï¼Œ<code>-j N</code> æ˜¯ job ä¸ªæ•°ï¼Œ<code>--no-checksum</code> ä¸æ£€æŸ¥æ–‡ä»¶ md5ï¼Œ<code>--editable</code> ä¸ºåœ¨ä¿®æ”¹è¿‡çš„æ–‡ä»¶åç»§ç»­ç¼–è¯‘ï¼Œä¸€èˆ¬åœ¨ <code>/tmp/root/spack-stage/spack-stage-amdscalapack-3.0-qwvyrumhsizxiaujwdsppcovijr5k5ri/spack-src/</code>. æœ‰äº›åŒ…æœ‰ cflags cxxflags fcflagsã€‚ æœ‰äº›æœ‰ cuda_archã€‚ç¢°åˆ°æ–°çš„è½¯ä»¶å¯ä»¥æŠŠæ‰€æœ‰éœ€è¦çš„å‚æ•° append åˆ°é‡Œé¢ã€‚</p>
<pre><code class="language-c">â¯ spack install -j 8 --no-checksum llvm+mlir+flang+all_targets+python+shared_libs cflags=&quot;-O3&quot; cxxflags=&quot;-O3&quot;
[+] /usr/local (external cmake-3.21.1-cdhzbrts4k5ylrvlpspfl75zgeht4swi)
[+] /Users/victoryang/spack/opt/spack/darwin-bigsur-skylake/apple-clang-12.0.5/libiconv-1.16-ropgshv657ooz7kfzojv4s6srscgimnw
[+] /usr/local (external pkg-config-0.29.2-4nv7fo7lbjybt2u3xzb2vxzvgvaz5xmw)
[+] /usr/local (external xz-5.2.5-p37wr6fna4ysoh2xn2wnmmzttm3bi37o)
[+] /Users/victoryang/spack/opt/spack/darwin-bigsur-skylake/apple-clang-12.0.5/zlib-1.2.11-lci2s4zd6x77rmexa3uuarbl5cvneskw
[+] /usr (external perl-5.30.2-4zkfgqml35km4ly7xmxn7ooz44dxtgqp)
[+] /usr/local (external python-3.9.6-shbb7dthsqe4lu26jugddyi2k7pl3jbl)
[+] /Users/victoryang/spack/opt/spack/darwin-bigsur-skylake/apple-clang-12.0.5/pcre-8.44-g4df4jqpudoxhjsrubrqhv3uwxajofet
[+] /usr/local (external z3-4.8.12-hvhfxnxuachtpi524zf55znqn55vanod)
[+] /Users/victoryang/spack/opt/spack/darwin-bigsur-skylake/apple-clang-12.0.5/ncurses-6.2-xilcz3bhw4otebvysduddyldezxhxvy6
[+] /Users/victoryang/spack/opt/spack/darwin-bigsur-skylake/apple-clang-12.0.5/libxml2-2.9.10-mlrnjcbnjt3w7635xrietes7terwhko6
[+] /Users/victoryang/spack/opt/spack/darwin-bigsur-skylake/apple-clang-12.0.5/perl-data-dumper-2.173-cv4kwshixb7tmk6p7icxrqpicppkx5gr
[+] /Users/victoryang/spack/opt/spack/darwin-bigsur-skylake/apple-clang-12.0.5/py-setuptools-50.3.2-hwyhyijgi3yjokddm67tb6aulefteudx
[+] /Users/victoryang/spack/opt/spack/darwin-bigsur-skylake/apple-clang-12.0.5/swig-4.0.2-vajpijk4isacr52dzgk2gqbvyunadwkc
[+] /Users/victoryang/spack/opt/spack/darwin-bigsur-skylake/apple-clang-12.0.5/libedit-3.1-20210216-6h4xokftdnxe2h3o7tie2cnbzbhfrr4h
[+] /Users/victoryang/spack/opt/spack/darwin-bigsur-skylake/apple-clang-12.0.5/hwloc-2.5.0-z2brjfcvnend5gorjmeqqgirccqerdwd
[+] /Users/victoryang/spack/opt/spack/darwin-bigsur-skylake/apple-clang-12.0.5/py-six-1.15.0-c63zkkdjpvegqai2f4jjg4mutsuchoov
[+] /Users/victoryang/spack/opt/spack/darwin-bigsur-skylake/apple-clang-12.0.5/llvm-12.0.1-n6c5z7sqfo7olnaqswu7jqhcdkyyk6nh
</code></pre>
<p>ä»¥ä¾èµ– nvhpc ç¼–è¯‘å™¨çš„ hdf5 ä¸ºä¾‹ã€‚ç¬”è€…ç¢°åˆ°çš„é—®é¢˜æœ‰ç»™å®š mpi æ‰¾ä¸åˆ°å¯¹åº” wrapper çš„ nvc ä»¥åŠ nvfortranã€‚åœ¨æ‰‹åŠ¨ç¼–è¯‘çš„æ—¶å€™ä¼šåœ¨ PATH é‡Œé¢æ‰¾ ccï¼Œæˆ–è€…ç›´æ¥æ‰¾ CCï¼ŒFCï¼ŒCXXã€‚è¿™æ—¶å€™éœ€è¦å®šä¹‰ä¸€ä¸ª FCã€‚</p>
<pre><code class="language-c">if spec.compiler.fc=&quot;nvfortran&quot;:
   env.set(&quot;FC&quot;,&quot;/path/to/mpifort wrapper&quot;)
   args.append((&quot;CMAKE_Fortran_COMPILER&quot;,spec.complier.mpifort))
</code></pre>
<p>åœ¨è¶…ç®—ä¸Šçš„ spack æœ‰ä¸¤ä¸ª upstreamï¼Œä½ è§‰å¾—é‡è¦å¯ä»¥ç›´æ¥ç»™åŸ repo PRï¼Œä¸€èˆ¬æˆ‘ä»¬å¤‡ä»½åˆ°å­¦æ ¡å†…éƒ¨çš„ gitlabã€‚</p>
<h4 id="spack-ä¸-modules"><a class="header" href="#spack-ä¸-modules">Spack ä¸ Modules</a></h4>
<p>å½“ç³»ç»Ÿæœ‰ Modules æ—¶ï¼Œä¼šè‡ªåŠ¨æŠŠ Module file çš„ç›®å½•åŠ åˆ° MANPATH ä¸‹ï¼Œä¹Ÿå³ç«‹å³å¯ä»¥ä½¿ç”¨ <code>module load</code></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="æœºå™¨ç®€ä»‹"><a class="header" href="#æœºå™¨ç®€ä»‹">æœºå™¨ç®€ä»‹</a></h1>
<pre><code class="language-bash">Architecture:        x86_64
CPU op-mode(s):      32-bit, 64-bit
Byte Order:          Little Endian
Address sizes:       43 bits physical, 48 bits virtual
CPU(s):              256
On-line CPU(s) list: 0-255
Thread(s) per core:  2
Core(s) per socket:  64
Socket(s):           2
NUMA node(s):        2
Vendor ID:           AuthenticAMD
CPU family:          23
Model:               49
Model name:          AMD EPYC 7742 64-Core Processor
Stepping:            0
CPU MHz:             2997.123
CPU max MHz:         2250.0000
CPU min MHz:         1500.0000
BogoMIPS:            4499.77
Virtualization:      AMD-V
L1d cache:           32K
L1i cache:           32K
L2 cache:            512K
L3 cache:            16384K
NUMA node0 CPU(s):   0-63,128-191
NUMA node1 CPU(s):   64-127,192-255
Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate sme ssbd sev ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif umip rdpid overflow_recov succor smca
</code></pre>
<pre><code class="language-bash">+-----------------------------------------------------------------------------+
| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA Tesla V1...  On   | 00000000:01:00.0 Off |                    0 |
| N/A   38C    P0    44W / 250W |  26730MiB / 32510MiB |    100%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA Tesla V1...  On   | 00000000:61:00.0 Off |                    0 |
| N/A   40C    P0    46W / 250W |  17711MiB / 32510MiB |     14%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA Tesla V1...  On   | 00000000:A1:00.0 Off |                    0 |
| N/A   47C    P0    53W / 250W |   7825MiB / 32510MiB |     74%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA Tesla V1...  On   | 00000000:C1:00.0 Off |                    0 |
| N/A   33C    P0    40W / 250W |   1255MiB / 32510MiB |    100%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A     47300      C   python                          25475MiB |
|    0   N/A  N/A    243387      C   ...ang2/anaconda3/bin/python     1251MiB |
|    1   N/A  N/A    102972      C   python                          17707MiB |
|    2   N/A  N/A    209376      C   python                           7821MiB |
|    3   N/A  N/A    243388      C   ...ang2/anaconda3/bin/python     1251MiB |
+-----------------------------------------------------------------------------+
</code></pre>
<pre><code class="language-bash">CA 'mlx5_0'
	CA type: MT4119
	Number of ports: 1
	Firmware version: 16.29.2002
	Hardware version: 0
	Node GUID: 0xb8599f0300e66b78
	System image GUID: 0xb8599f0300e66b78
	Port 1:
		State: Active
		Physical state: LinkUp
		Rate: 100
		Base lid: 1
		LMC: 0
		SM lid: 6
		Capability mask: 0x2651e84a
		Port GUID: 0xb8599f0300e66b78
		Link layer: InfiniBand
</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        
                        
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                
                            </nav>

        </div>

        
        
        
                <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        
        
                <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        
                        <script type="text/javascript">
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>
                
    </body>
</html>
